{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "675e76ac-3df7-4907-965b-0734ce930776",
   "metadata": {},
   "source": [
    "### Name:\n",
    "> Castillo, Marvien Angel C. <br>\n",
    "> Herrera, Mikhaela Gabrielle B. <br>\n",
    "> Regindin, Sean Adrien I. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ca5222-52aa-4427-9c3b-af43cc723425",
   "metadata": {},
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b62a7b9-a7dd-4fe8-bd35-14496766e694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/bin:/bin:/usr/bin:/usr/local/cuda/bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Add the directory containing the executable to the PATH\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/usr/local/cuda/bin\"\n",
    "\n",
    "# Check if the directory is added to the PATH\n",
    "print(os.environ[\"PATH\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b00f5-9708-40c2-a38d-0c8e34ab5ce7",
   "metadata": {},
   "source": [
    "# Check if CUDA is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "527bdb74-686d-45e2-af5f-ffa4e5722547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2025 NVIDIA Corporation\n",
      "Built on Wed_Apr__9_19:24:57_PDT_2025\n",
      "Cuda compilation tools, release 12.9, V12.9.41\n",
      "Build cuda_12.9.r12.9/compiler.35813241_0\n",
      "nvprof: NVIDIA (R) Cuda command line profiler\n",
      "Copyright (c) 2012 - 2025 NVIDIA Corporation\n",
      "Release version 12.9.19 (21)\n",
      "NVIDIA Nsight Systems version 2025.1.3.140-251335620677v0\n",
      "NVIDIA (R) Nsight Compute Command Line Profiler\n",
      "Copyright (c) 2018-2025 NVIDIA Corporation\n",
      "Version 2025.2.0.0 (build 35613519) (public-release)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvcc --version\n",
    "nvprof --version\n",
    "nsys --version\n",
    "ncu --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d42504cd-6133-426b-8259-bc8b29f494a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov  6 06:01:50 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.51.03              Driver Version: 575.51.03      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           Off |   00000000:00:10.0 Off |                    0 |\n",
      "| N/A   27C    P0             22W /  250W |       0MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d88540-e0ee-436f-bf98-9ca39515d4e7",
   "metadata": {},
   "source": [
    "# Variant 1 - C Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e971dfd-51ea-442b-9e10-8c56a98da76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C_var1.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile C_var1.c\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "#include <math.h>\n",
    "// ***C function version\n",
    "void kernel_C(float A[], float B[], float C[], size_t n, int idx[]) {\n",
    "\tfor (int i = 0; i < n; i++) {\n",
    "\t\tif (A[i] >= B[i]) {\n",
    "\t\t\tC[i] = A[i];\n",
    "\t\t\tidx[i] = 0;\n",
    "\t\t}\n",
    "\t\telse {\n",
    "\t\t\tC[i] = B[i];\n",
    "\t\t\tidx[i] = 1;\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "int main(int argc, char** argv)\n",
    "{\n",
    "   const size_t ARRAY_SIZE = 1<<24;\n",
    "   const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "   const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    "//number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "   float *C,*A,*B;\n",
    "   int *idx,a;\n",
    "   A = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "   B = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "   C = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "   idx = (int*)malloc(INT_ARRAY_BYTES);\n",
    "   a=2;\n",
    "//timer variables\n",
    "  clock_t start, end;\n",
    "// ***--- initialize your array here ---------\n",
    "   int i;\n",
    "\tfor (i = 0; i < ARRAY_SIZE; i++) {\n",
    "\t\tA[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "\t\tB[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "\t}\n",
    "// fill-in cache\n",
    "    kernel_C(A,B,C,ARRAY_SIZE,idx);\n",
    "//time here\n",
    "  double elapse, time_taken;\n",
    "  elapse = 0.0f;\n",
    "  for (int i=0; i<loope; i++){\n",
    "    start = clock();\n",
    "      kernel_C(A,B,C,ARRAY_SIZE,idx );\n",
    "    end = clock();\n",
    "    time_taken = ((double)(end-start))*1E3/CLOCKS_PER_SEC;\n",
    "    elapse = elapse + time_taken;\n",
    "  }\n",
    "  printf(\"Function (in C) average time for %lu loops is %f milliseconds to execute an array size %lu \\n\", loope, elapse/loope, ARRAY_SIZE);\n",
    "\n",
    "// error checking routine here --\n",
    "   size_t err_count = 0;\n",
    "   int sanity_checker = 0;\n",
    "   for (int i = 0; i < ARRAY_SIZE; i++) { \n",
    "        float expected_C = (A[i] >= B[i]) ? A[i] : B[i];\n",
    "        int expected_idx = (A[i] >= B[i]) ? 0 : 1;\n",
    "    \n",
    "        if (fabs(C[i] - expected_C) > 1e-5 || idx[i] != expected_idx) {\n",
    "            sanity_checker++;\n",
    "        }\n",
    "    }\n",
    "  printf(\"Sanity Checker = %d\",sanity_checker);\n",
    "  \n",
    "  // Free memory\n",
    "  free(A);\n",
    "  free(B);\n",
    "  free(C);\n",
    "  free(idx);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2937bac-9c8c-4743-8fdc-a70382f397bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcc C_var1.c -o C_var1 -lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c618468c-6a90-48c3-8f9c-2f718297f72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function (in C) average time for 10 loops is 216.433500 milliseconds to execute an array size 16777216 \n",
      "Sanity Checker = 0"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./C_var1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b7521-df56-4266-b663-02eb5447f81f",
   "metadata": {},
   "source": [
    "# Variant 2 - Grid Stride Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffa6ecb3-ed9b-4fdd-a509-392a3dc709e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_var2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_var2.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "//Grid stride loop\n",
    "\n",
    "//*** CUDA kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "  float *A,*B,*C; \n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, INT_ARRAY_BYTES);\n",
    "// *** init array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    A[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "    B[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    "\n",
    "// *** setup CUDA kernel\n",
    "  size_t numThreads = 1024;\n",
    "  size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function = Float kernel_C\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks,numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    kernel_C <<<numBlocks, numThreads>>> (ARRAY_SIZE,A,B,C,idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize();\n",
    "  int sanity_checker = 0;\n",
    "  for (int i = 0; i < ARRAY_SIZE; i++) { \n",
    "        float expected_C = (A[i] >= B[i]) ? A[i] : B[i];\n",
    "        int expected_idx = (A[i] >= B[i]) ? 0 : 1;\n",
    "    \n",
    "        if (fabs(C[i] - expected_C) > 1e-5 || idx[i] != expected_idx) {\n",
    "            sanity_checker++;\n",
    "        }\n",
    "    }\n",
    "  printf(\"Sanity Checker = %d\",sanity_checker);\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(C);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c558b99-9904-4214-addc-f54781b834ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var2.cu -o CUDA_var2 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc02147f-9af0-4a66-82d7-025fb0c4d9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1029411== NVPROF is profiling process 1029411, command: ./CUDA_var2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = Float kernel_C\n",
      "numElements = 16777216\n",
      "numBlocks = 16384, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n",
      "Sanity Checker = 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1029411== Profiling application: ./CUDA_var2\n",
      "==1029411== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  121.64ms        10  12.164ms  343.23us  118.54ms  kernel_C(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   92.34%  1.84365s         4  460.91ms  96.183us  1.84151s  cudaMallocManaged\n",
      "                    6.08%  121.47ms         1  121.47ms  121.47ms  121.47ms  cudaDeviceSynchronize\n",
      "                    1.38%  27.578ms         4  6.8945ms  6.8165ms  7.0277ms  cudaFree\n",
      "                    0.12%  2.4785ms        10  247.85us  13.916us  2.2560ms  cudaLaunchKernel\n",
      "                    0.04%  819.71us       114  7.1900us     132ns  320.00us  cuDeviceGetAttribute\n",
      "                    0.02%  321.05us         1  321.05us  321.05us  321.05us  cuDeviceGetName\n",
      "                    0.01%  169.63us         2  84.816us  6.8810us  162.75us  cuDeviceGet\n",
      "                    0.01%  110.88us         1  110.88us  110.88us  110.88us  cuDeviceTotalMem\n",
      "                    0.00%  13.432us         1  13.432us  13.432us  13.432us  cuDeviceGetPCIBusId\n",
      "                    0.00%  13.198us         3  4.3990us     228ns  8.8080us  cuDeviceGetCount\n",
      "                    0.00%  1.7180us         1  1.7180us  1.7180us  1.7180us  cuModuleGetLoadingMode\n",
      "                    0.00%     381ns         1     381ns     381ns     381ns  cuDeviceGetUuid\n",
      "\n",
      "==1029411== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "    4888  25.494KB  4.0000KB  0.9961MB  121.6953MB  38.54171ms  Host To Device\n",
      "    1685  155.43KB  4.0000KB  0.9961MB  255.7539MB  91.57850ms  Device To Host\n",
      "Total CPU Page faults: 1149\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcba6431-ecfa-4d1d-8767-9b07a9110d17",
   "metadata": {},
   "source": [
    "# Variant 3.0 - Grid Stride Loop with Prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d448a7f2-2596-42d1-b7aa-4b6618348517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_var3.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_var3.cu\n",
    "// prefetch\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "//CUDA kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "  float *A,*B,*C; \n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, INT_ARRAY_BYTES);\n",
    "\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "// ****init array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    A[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "    B[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    " //\"Prefetch data\" from CPU-GPU\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// setup CUDA kernel\n",
    "    size_t numThreads = 1024;\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function ***\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks, numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    kernel_C <<<numBlocks, numThreads>>> (ARRAY_SIZE,A,B,C,idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize(); \n",
    "\n",
    "//\"Prefetch data\" from GPU-CPU\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "\n",
    "  int sanity_checker = 0;\n",
    "  for (int i = 0; i < ARRAY_SIZE; i++) { \n",
    "        float expected_C = (A[i] >= B[i]) ? A[i] : B[i];\n",
    "        int expected_idx = (A[i] >= B[i]) ? 0 : 1;\n",
    "    \n",
    "        if (fabs(C[i] - expected_C) > 1e-5 || idx[i] != expected_idx) {\n",
    "            sanity_checker++;\n",
    "        }\n",
    "    }\n",
    "  printf(\"Sanity Checker = %d\",sanity_checker);\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(C);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcc20dc8-3622-46ec-9924-ae5fb7035e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var3.cu -o CUDA_var3 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aafe0fd-a19c-4eb8-865b-284ed0604610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1029474== NVPROF is profiling process 1029474, command: ./CUDA_var3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function ***\n",
      "numElements = 16777216\n",
      "numBlocks = 16384, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n",
      "Sanity Checker = 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1029474== Profiling application: ./CUDA_var3\n",
      "==1029474== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  3.5372ms        10  353.72us  351.49us  357.69us  kernel_C(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   86.38%  1.34499s         4  336.25ms  49.601us  1.34403s  cudaMallocManaged\n",
      "                   10.70%  166.56ms         8  20.820ms  17.280us  50.832ms  cudaMemPrefetchAsync\n",
      "                    1.70%  26.521ms         4  6.6303ms  5.2011ms  7.4492ms  cudaFree\n",
      "                    0.96%  14.982ms        10  1.4982ms  16.385us  14.784ms  cudaLaunchKernel\n",
      "                    0.22%  3.3656ms         1  3.3656ms  3.3656ms  3.3656ms  cudaDeviceSynchronize\n",
      "                    0.03%  438.96us       114  3.8500us     116ns  169.75us  cuDeviceGetAttribute\n",
      "                    0.01%  119.81us         1  119.81us  119.81us  119.81us  cuDeviceGetName\n",
      "                    0.00%  24.232us         1  24.232us  24.232us  24.232us  cuDeviceTotalMem\n",
      "                    0.00%  23.193us         1  23.193us  23.193us  23.193us  cuDeviceGetPCIBusId\n",
      "                    0.00%  22.457us         1  22.457us  22.457us  22.457us  cudaGetDevice\n",
      "                    0.00%  6.5780us         3  2.1920us     141ns  5.9840us  cuDeviceGetCount\n",
      "                    0.00%  5.7110us         2  2.8550us     195ns  5.5160us  cuDeviceGet\n",
      "                    0.00%     791ns         1     791ns     791ns     791ns  cuModuleGetLoadingMode\n",
      "                    0.00%     231ns         1     231ns     231ns     231ns  cuDeviceGetUuid\n",
      "\n",
      "==1029474== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  18.69442ms  Host To Device\n",
      "     128  2.0000MB  2.0000MB  2.0000MB  256.0000MB  137.5592ms  Device To Host\n",
      "Total CPU Page faults: 384\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5373b40-2dbb-40a8-a641-e01f1475922a",
   "metadata": {},
   "source": [
    "# Variant 4.0 - Grid Stride Loop with Prefetch and Page Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "020a7737-1ddb-4031-9e4d-f99222e66b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_var4.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_var4.cu\n",
    "//prefetch + page creation\n",
    "// page creation responsible gpu fault page\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "//CUDA kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "  float *A,*B,*C; \n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, INT_ARRAY_BYTES);\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "//\"prefetch data\" to create CPU page memory\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "//\"prefetch data\" to create GPU page memory\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// ****init array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    A[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "    B[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    "//\"Prefetch data\" from CPU-GPU\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// setup CUDA kernel\n",
    "    size_t numThreads = 1024;   \n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function ***\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks, numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    kernel_C <<<numBlocks, numThreads>>> (ARRAY_SIZE,A,B,C,idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "  //\"Prefetch data\" from GPU-CPU\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "\n",
    "  int sanity_checker = 0;\n",
    "  for (int i = 0; i < ARRAY_SIZE; i++) { \n",
    "        float expected_C = (A[i] >= B[i]) ? A[i] : B[i];\n",
    "        int expected_idx = (A[i] >= B[i]) ? 0 : 1;\n",
    "    \n",
    "        if (fabs(C[i] - expected_C) > 1e-5 || idx[i] != expected_idx) {\n",
    "            sanity_checker++;\n",
    "        }\n",
    "    }\n",
    "  printf(\"Sanity Checker = %d\",sanity_checker);\n",
    "\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(C);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "853e10b1-540f-4ed3-aaa1-15c930185f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var4.cu -o CUDA_var4 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f28773e4-33f5-4f41-bc23-aa056be9ffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1029542== NVPROF is profiling process 1029542, command: ./CUDA_var4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function ***\n",
      "numElements = 16777216\n",
      "numBlocks = 16384, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n",
      "Sanity Checker = 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1029542== Profiling application: ./CUDA_var4\n",
      "==1029542== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  3.6539ms        10  365.39us  363.52us  368.93us  kernel_C(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   81.20%  1.61421s         4  403.55ms  61.586us  1.61294s  cudaMallocManaged\n",
      "                   16.87%  335.35ms        12  27.946ms  24.579us  82.191ms  cudaMemPrefetchAsync\n",
      "                    0.99%  19.707ms         4  4.9268ms  3.9704ms  6.4406ms  cudaFree\n",
      "                    0.71%  14.101ms        10  1.4101ms  10.534us  13.927ms  cudaLaunchKernel\n",
      "                    0.18%  3.5237ms         1  3.5237ms  3.5237ms  3.5237ms  cudaDeviceSynchronize\n",
      "                    0.03%  614.96us       114  5.3940us     127ns  241.68us  cuDeviceGetAttribute\n",
      "                    0.01%  240.02us         1  240.02us  240.02us  240.02us  cuDeviceGetName\n",
      "                    0.01%  136.75us         1  136.75us  136.75us  136.75us  cudaGetDevice\n",
      "                    0.00%  55.467us         1  55.467us  55.467us  55.467us  cuDeviceTotalMem\n",
      "                    0.00%  25.292us         1  25.292us  25.292us  25.292us  cuDeviceGetPCIBusId\n",
      "                    0.00%  11.544us         3  3.8480us     264ns  7.9830us  cuDeviceGetCount\n",
      "                    0.00%  7.5940us         2  3.7970us     573ns  7.0210us  cuDeviceGet\n",
      "                    0.00%     994ns         1     994ns     994ns     994ns  cuDeviceGetUuid\n",
      "                    0.00%     831ns         1     831ns     831ns     831ns  cuModuleGetLoadingMode\n",
      "\n",
      "==1029542== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  19.53981ms  Host To Device\n",
      "     128  2.0000MB  2.0000MB  2.0000MB  256.0000MB  123.2244ms  Device To Host\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf27c3d-526d-4752-9109-314ead58f1b0",
   "metadata": {},
   "source": [
    "# Variant 5.0 - Grid Stride Loop with Prefetch and Page Creation + mem advise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "164372f7-2a1d-4683-8c52-6607404c7c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_var5.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_var5.cu\n",
    "//prefetch + page creation + memadvise\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "//CUDA kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "  float *A,*B,*C; \n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, INT_ARRAY_BYTES);\n",
    "\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "// memory advise\n",
    "   cudaMemAdvise(A, FLOAT_ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
    "   cudaMemAdvise(A, FLOAT_ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
    "   cudaMemAdvise(B, FLOAT_ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
    "   cudaMemAdvise(B, FLOAT_ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
    "\n",
    "//\"prefetch data\" to create CPU page memory\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "//\"prefetch data\" to create GPU page memory\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// ****init array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    A[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "    B[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    "\n",
    "\n",
    " //\"Prefetch data\" from CPU-GPU\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// setup CUDA kernel\n",
    "    size_t numThreads = 1024;   // what if numThreads>1024, numThreads<1024?\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function ***\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks, numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    kernel_C <<<numBlocks, numThreads>>> (ARRAY_SIZE,A,B,C,idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "  //\"Prefetch data\" from GPU-CPU\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "\n",
    "\n",
    "  int sanity_checker = 0;\n",
    "  for (int i = 0; i < ARRAY_SIZE; i++) { \n",
    "        float expected_C = (A[i] >= B[i]) ? A[i] : B[i];\n",
    "        int expected_idx = (A[i] >= B[i]) ? 0 : 1;\n",
    "    \n",
    "        if (fabs(C[i] - expected_C) > 1e-5 || idx[i] != expected_idx) {\n",
    "            sanity_checker++;\n",
    "        }\n",
    "    }\n",
    "  printf(\"Sanity Checker = %d\",sanity_checker);\n",
    "\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(C);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fd4a82f-8d7e-44ff-a297-f144050f2718",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var5.cu -o CUDA_var5 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19dc4c29-d16f-4529-a1c9-36c8ade23ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1030060== NVPROF is profiling process 1030060, command: ./CUDA_var5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function ***\n",
      "numElements = 16777216\n",
      "numBlocks = 16384, numThreads = 1024 \n",
      "Sanity Checker = 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1030060== Profiling application: ./CUDA_var5\n",
      "==1030060== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  3.6554ms        10  365.54us  362.75us  369.47us  kernel_C(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   81.04%  1.48778s         4  371.95ms  87.888us  1.48727s  cudaMallocManaged\n",
      "                   16.51%  303.05ms        12  25.254ms  196.99us  76.991ms  cudaMemPrefetchAsync\n",
      "                    2.03%  37.232ms         4  9.3079ms  6.8002ms  12.693ms  cudaFree\n",
      "                    0.20%  3.5807ms         1  3.5807ms  3.5807ms  3.5807ms  cudaDeviceSynchronize\n",
      "                    0.13%  2.4616ms        10  246.16us  7.6480us  2.3594ms  cudaLaunchKernel\n",
      "                    0.07%  1.2301ms       114  10.790us     159ns  655.91us  cuDeviceGetAttribute\n",
      "                    0.01%  192.43us         1  192.43us  192.43us  192.43us  cuDeviceGetName\n",
      "                    0.01%  176.62us         4  44.156us  13.598us  125.97us  cudaMemAdvise\n",
      "                    0.00%  58.591us         1  58.591us  58.591us  58.591us  cuDeviceTotalMem\n",
      "                    0.00%  18.990us         1  18.990us  18.990us  18.990us  cuDeviceGetPCIBusId\n",
      "                    0.00%  13.634us         1  13.634us  13.634us  13.634us  cudaGetDevice\n",
      "                    0.00%  12.786us         3  4.2620us     217ns  6.3630us  cuDeviceGetCount\n",
      "                    0.00%  8.6640us         2  4.3320us  1.3160us  7.3480us  cuDeviceGet\n",
      "                    0.00%     738ns         1     738ns     738ns     738ns  cuDeviceGetUuid\n",
      "                    0.00%     548ns         1     548ns     548ns     548ns  cuModuleGetLoadingMode\n",
      "\n",
      "==1030060== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  16.75434ms  Host To Device\n",
      "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  65.10607ms  Device To Host\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88115767-5ecc-4555-9db7-1ed69bcf01bc",
   "metadata": {},
   "source": [
    "# Variant 6.0 - CUDA classic MEMCPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a4aabf3-01a1-43d9-9ad2-53b22d5623a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_var6.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_var6.cu\n",
    "//grid stride loop + memcpy\n",
    "// BFF PALANG TOH SO FAR + onting research sa websites HJSHAS\n",
    "// UNFINISHED\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "\n",
    "//CUDA kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "\n",
    "float *h_A = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "float *h_B = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "float *h_C = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "int *h_idx = (int*)malloc(INT_ARRAY_BYTES);\n",
    "\n",
    "// ****init host array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    h_A[i] = sinf(i * 0.0005) * 100.0 + 50.0;\n",
    "    h_B[i] = cosf(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    "\n",
    "// device allocations\n",
    "  float *d_A,*d_B,*d_C;\n",
    "  int *d_idx;\n",
    "  cudaMalloc(&d_A, FLOAT_ARRAY_BYTES); //we dont use cudaMallocManaged with cudaMemcpy\n",
    "  cudaMalloc(&d_B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMalloc(&d_C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMalloc(&d_idx, INT_ARRAY_BYTES);\n",
    "\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "// Copy data to device\n",
    "    cudaMemcpy(d_A, h_A, FLOAT_ARRAY_BYTES, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_B, h_B, FLOAT_ARRAY_BYTES, cudaMemcpyHostToDevice);\n",
    "\n",
    "// Kernel launch configuration\n",
    "    int threadsPerBlock = 256;\n",
    "    int blocksPerGrid = (ARRAY_SIZE + threadsPerBlock - 1) / threadsPerBlock;\n",
    "    \n",
    "  for (size_t i=0; i<loope;i++){\n",
    "    kernel_C <<<blocksPerGrid, threadsPerBlock>>> (ARRAY_SIZE, d_A, d_B, d_C, d_idx);\n",
    "    cudaDeviceSynchronize();\n",
    "  }\n",
    "\n",
    "    \n",
    "// Copy results back to host\n",
    "    cudaMemcpy(h_C, d_C, FLOAT_ARRAY_BYTES, cudaMemcpyDeviceToHost);\n",
    "    cudaMemcpy(h_idx, d_idx, INT_ARRAY_BYTES, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Verification loop\n",
    "    int errors = 0;\n",
    "    for (int i = 0; i < ARRAY_SIZE; i++) { \n",
    "        float expected_C = (h_A[i] >= h_B[i]) ? h_A[i] : h_B[i];\n",
    "        int expected_idx = (h_A[i] >= h_B[i]) ? 0 : 1;\n",
    "    \n",
    "        if (fabs(h_C[i] - expected_C) > 1e-5 || h_idx[i] != expected_idx) {\n",
    "            errors++;\n",
    "        }\n",
    "    }\n",
    "    printf(\"Errors = %d\", errors);\n",
    "\n",
    "// Free device memory\n",
    "    cudaFree(d_A);\n",
    "    cudaFree(d_B);\n",
    "    cudaFree(d_C);\n",
    "    cudaFree(d_idx);\n",
    "\n",
    "// Free host memory\n",
    "    free(h_A);\n",
    "    free(h_B);\n",
    "    free(h_C);\n",
    "    free(h_idx);\n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a5719731-db6c-40a0-aabf-ebded2ba59e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var6.cu -o CUDA_var6 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "82fb784d-b5ec-4cc1-b9f6-ae8ee8c4b303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors = 0"
     ]
    }
   ],
   "source": [
    "!./CUDA_var6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a975380-63c1-456d-83cd-cc864431ccd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1025309== NVPROF is profiling process 1025309, command: ./CUDA_var6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors = 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1025309== Profiling application: ./CUDA_var6\n",
      "==1025309== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   73.64%  507.42ms         2  253.71ms  247.51ms  259.91ms  [CUDA memcpy DtoH]\n",
      "                   25.86%  178.22ms         2  89.109ms  63.545ms  114.67ms  [CUDA memcpy HtoD]\n",
      "                    0.50%  3.4523ms        10  345.23us  343.58us  349.02us  kernel_C(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   62.67%  1.19623s         4  299.06ms  209.42us  1.19512s  cudaMalloc\n",
      "                   36.78%  702.08ms         4  175.52ms  65.015ms  265.80ms  cudaMemcpy\n",
      "                    0.19%  3.5435ms        10  354.35us  335.69us  410.42us  cudaDeviceSynchronize\n",
      "                    0.18%  3.4627ms         4  865.68us  498.18us  1.3809ms  cudaFree\n",
      "                    0.12%  2.2218ms        10  222.18us  12.424us  2.0468ms  cudaLaunchKernel\n",
      "                    0.04%  714.79us       114  6.2700us     124ns  290.33us  cuDeviceGetAttribute\n",
      "                    0.01%  245.00us         1  245.00us  245.00us  245.00us  cuDeviceGetName\n",
      "                    0.00%  70.748us         1  70.748us  70.748us  70.748us  cuDeviceTotalMem\n",
      "                    0.00%  51.929us         1  51.929us  51.929us  51.929us  cuDeviceGetPCIBusId\n",
      "                    0.00%  14.872us         2  7.4360us     195ns  14.677us  cuDeviceGet\n",
      "                    0.00%  10.583us         3  3.5270us     109ns  9.5610us  cuDeviceGetCount\n",
      "                    0.00%  6.4810us         1  6.4810us  6.4810us  6.4810us  cudaGetDevice\n",
      "                    0.00%  1.2470us         1  1.2470us  1.2470us  1.2470us  cuModuleGetLoadingMode\n",
      "                    0.00%  1.0280us         1  1.0280us  1.0280us  1.0280us  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d35ab59-801c-4a6b-a164-3373f33cfaed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
