{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "675e76ac-3df7-4907-965b-0734ce930776",
   "metadata": {},
   "source": [
    "### Name:\n",
    "> Castillo, Marvien Angel C. <br>\n",
    "> Herrera, Mikhaela Gabrielle B. <br>\n",
    "> Regindin, Sean Adrien I. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ca5222-52aa-4427-9c3b-af43cc723425",
   "metadata": {},
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b62a7b9-a7dd-4fe8-bd35-14496766e694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/bin:/bin:/usr/bin:/usr/local/cuda/bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Add the directory containing the executable to the PATH\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/usr/local/cuda/bin\"\n",
    "\n",
    "# Check if the directory is added to the PATH\n",
    "print(os.environ[\"PATH\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b00f5-9708-40c2-a38d-0c8e34ab5ce7",
   "metadata": {},
   "source": [
    "# Check if CUDA is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "527bdb74-686d-45e2-af5f-ffa4e5722547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2025 NVIDIA Corporation\n",
      "Built on Wed_Apr__9_19:24:57_PDT_2025\n",
      "Cuda compilation tools, release 12.9, V12.9.41\n",
      "Build cuda_12.9.r12.9/compiler.35813241_0\n",
      "nvprof: NVIDIA (R) Cuda command line profiler\n",
      "Copyright (c) 2012 - 2025 NVIDIA Corporation\n",
      "Release version 12.9.19 (21)\n",
      "NVIDIA Nsight Systems version 2025.1.3.140-251335620677v0\n",
      "NVIDIA (R) Nsight Compute Command Line Profiler\n",
      "Copyright (c) 2018-2025 NVIDIA Corporation\n",
      "Version 2025.2.0.0 (build 35613519) (public-release)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvcc --version\n",
    "nvprof --version\n",
    "nsys --version\n",
    "ncu --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d42504cd-6133-426b-8259-bc8b29f494a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov  6 08:25:10 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.51.03              Driver Version: 575.51.03      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           Off |   00000000:00:10.0 Off |                    0 |\n",
      "| N/A   26C    P0             22W /  250W |       0MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d88540-e0ee-436f-bf98-9ca39515d4e7",
   "metadata": {},
   "source": [
    "# Variant 1 - C Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e971dfd-51ea-442b-9e10-8c56a98da76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C_var1.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile C_var1.c\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "#include <math.h>\n",
    "// ***C function version\n",
    "void kernel_C(float A[], float B[], float C[], size_t n, int idx[]) {\n",
    "\tfor (int i = 0; i < n; i++) {\n",
    "\t\tif (A[i] >= B[i]) {\n",
    "\t\t\tC[i] = A[i];\n",
    "\t\t\tidx[i] = 0;\n",
    "\t\t}\n",
    "\t\telse {\n",
    "\t\t\tC[i] = B[i];\n",
    "\t\t\tidx[i] = 1;\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "int main(int argc, char** argv)\n",
    "{\n",
    "   const size_t ARRAY_SIZE = 1<<24;\n",
    "   const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "   const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    "//number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "   float *C,*A,*B;\n",
    "   int *idx,a;\n",
    "   A = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "   B = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "   C = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "   idx = (int*)malloc(INT_ARRAY_BYTES);\n",
    "   a=2;\n",
    "//timer variables\n",
    "  clock_t start, end;\n",
    "// ***--- initialize your array here ---------\n",
    "   int i;\n",
    "\tfor (i = 0; i < ARRAY_SIZE; i++) {\n",
    "\t\tA[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "\t\tB[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "\t}\n",
    "// fill-in cache\n",
    "    kernel_C(A,B,C,ARRAY_SIZE,idx);\n",
    "//time here\n",
    "  double elapse, time_taken;\n",
    "  elapse = 0.0f;\n",
    "  for (int i=0; i<loope; i++){\n",
    "    start = clock();\n",
    "      kernel_C(A,B,C,ARRAY_SIZE,idx );\n",
    "    end = clock();\n",
    "    time_taken = ((double)(end-start))*1E3/CLOCKS_PER_SEC;\n",
    "    elapse = elapse + time_taken;\n",
    "  }\n",
    "  printf(\"Function (in C) average time for %lu loops is %f milliseconds to execute an array size %lu \\n\", loope, elapse/loope, ARRAY_SIZE);\n",
    "\n",
    "// error checking routine here --\n",
    "   size_t err_count = 0;\n",
    "   int sanity_checker = 0;\n",
    "   for (int i = 0; i < ARRAY_SIZE; i++) { \n",
    "        float expected_C = (A[i] >= B[i]) ? A[i] : B[i];\n",
    "        int expected_idx = (A[i] >= B[i]) ? 0 : 1;\n",
    "    \n",
    "        if (fabs(C[i] - expected_C) > 1e-5 || idx[i] != expected_idx) {\n",
    "            sanity_checker++;\n",
    "        }\n",
    "    }\n",
    "  printf(\"Sanity Checker = %d\",sanity_checker);\n",
    "  \n",
    "  // Free memory\n",
    "  free(A);\n",
    "  free(B);\n",
    "  free(C);\n",
    "  free(idx);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2937bac-9c8c-4743-8fdc-a70382f397bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcc C_var1.c -o C_var1 -lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c618468c-6a90-48c3-8f9c-2f718297f72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function (in C) average time for 10 loops is 287.938900 milliseconds to execute an array size 16777216 \n",
      "Sanity Checker = 0"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./C_var1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b7521-df56-4266-b663-02eb5447f81f",
   "metadata": {},
   "source": [
    "# Variant 2 - Grid Stride Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffa6ecb3-ed9b-4fdd-a509-392a3dc709e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_var2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_var2.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "//Grid stride loop\n",
    "\n",
    "//*** CUDA kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "  float *A,*B,*C; \n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, INT_ARRAY_BYTES);\n",
    "// *** init array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    A[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "    B[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    "\n",
    "// *** setup CUDA kernel\n",
    "  size_t numThreads = 1024;\n",
    "  size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function = Float kernel_C\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks,numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    kernel_C <<<numBlocks, numThreads>>> (ARRAY_SIZE,A,B,C,idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize();\n",
    "  int sanity_checker = 0;\n",
    "  for (int i = 0; i < ARRAY_SIZE; i++) { \n",
    "        float expected_C = (A[i] >= B[i]) ? A[i] : B[i];\n",
    "        int expected_idx = (A[i] >= B[i]) ? 0 : 1;\n",
    "    \n",
    "        if (fabs(C[i] - expected_C) > 1e-5 || idx[i] != expected_idx) {\n",
    "            sanity_checker++;\n",
    "        }\n",
    "    }\n",
    "  printf(\"Sanity Checker = %d\",sanity_checker);\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(C);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c558b99-9904-4214-addc-f54781b834ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var2.cu -o CUDA_var2 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc02147f-9af0-4a66-82d7-025fb0c4d9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1031626== NVPROF is profiling process 1031626, command: ./CUDA_var2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = Float kernel_C\n",
      "numElements = 16777216\n",
      "numBlocks = 16384, numThreads = 1024 \n",
      "Sanity Checker = 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1031626== Profiling application: ./CUDA_var2\n",
      "==1031626== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  132.99ms        10  13.299ms  343.52us  129.89ms  kernel_C(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   91.09%  1.80177s         4  450.44ms  105.07us  1.80057s  cudaMallocManaged\n",
      "                    6.71%  132.73ms         1  132.73ms  132.73ms  132.73ms  cudaDeviceSynchronize\n",
      "                    1.93%  38.275ms         4  9.5687ms  8.8571ms  10.552ms  cudaFree\n",
      "                    0.22%  4.3335ms        10  433.35us  19.137us  4.0328ms  cudaLaunchKernel\n",
      "                    0.04%  750.17us       114  6.5800us     120ns  288.82us  cuDeviceGetAttribute\n",
      "                    0.01%  140.62us         1  140.62us  140.62us  140.62us  cuDeviceGetName\n",
      "                    0.00%  31.837us         1  31.837us  31.837us  31.837us  cuDeviceGetPCIBusId\n",
      "                    0.00%  29.756us         1  29.756us  29.756us  29.756us  cuDeviceTotalMem\n",
      "                    0.00%  10.664us         3  3.5540us     136ns  9.8390us  cuDeviceGetCount\n",
      "                    0.00%  8.7200us         2  4.3600us     357ns  8.3630us  cuDeviceGet\n",
      "                    0.00%  1.5060us         1  1.5060us  1.5060us  1.5060us  cuDeviceGetUuid\n",
      "                    0.00%     759ns         1     759ns     759ns     759ns  cuModuleGetLoadingMode\n",
      "\n",
      "==1031626== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "    5251  24.961KB  4.0000KB  0.9961MB  128.0000MB  51.33748ms  Host To Device\n",
      "    1536  170.67KB  4.0000KB  0.9961MB  256.0000MB  107.7273ms  Device To Host\n",
      "     185         -         -         -           -  129.6010ms  Gpu page fault groups\n",
      "Total CPU Page faults: 1152\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcba6431-ecfa-4d1d-8767-9b07a9110d17",
   "metadata": {},
   "source": [
    "# Variant 3.0 - Grid Stride Loop with Prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d448a7f2-2596-42d1-b7aa-4b6618348517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_var3.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_var3.cu\n",
    "// prefetch\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "//CUDA kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "  float *A,*B,*C; \n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, INT_ARRAY_BYTES);\n",
    "\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "// ****init array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    A[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "    B[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    " //\"Prefetch data\" from CPU-GPU\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// setup CUDA kernel\n",
    "    size_t numThreads = 1024;\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function ***\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks, numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    kernel_C <<<numBlocks, numThreads>>> (ARRAY_SIZE,A,B,C,idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize(); \n",
    "\n",
    "//\"Prefetch data\" from GPU-CPU\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "\n",
    "  int sanity_checker = 0;\n",
    "  for (int i = 0; i < ARRAY_SIZE; i++) { \n",
    "        float expected_C = (A[i] >= B[i]) ? A[i] : B[i];\n",
    "        int expected_idx = (A[i] >= B[i]) ? 0 : 1;\n",
    "    \n",
    "        if (fabs(C[i] - expected_C) > 1e-5 || idx[i] != expected_idx) {\n",
    "            sanity_checker++;\n",
    "        }\n",
    "    }\n",
    "  printf(\"Sanity Checker = %d\",sanity_checker);\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(C);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcc20dc8-3622-46ec-9924-ae5fb7035e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var3.cu -o CUDA_var3 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aafe0fd-a19c-4eb8-865b-284ed0604610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1031681== NVPROF is profiling process 1031681, command: ./CUDA_var3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function ***\n",
      "numElements = 16777216\n",
      "numBlocks = 16384, numThreads = 1024 \n",
      "Sanity Checker = 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1031681== Profiling application: ./CUDA_var3\n",
      "==1031681== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  3.5414ms        10  354.14us  351.36us  359.26us  kernel_C(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   85.45%  1.74109s         4  435.27ms  54.518us  1.74009s  cudaMallocManaged\n",
      "                   12.21%  248.79ms         8  31.098ms  14.779us  81.622ms  cudaMemPrefetchAsync\n",
      "                    1.14%  23.296ms         4  5.8239ms  4.7439ms  7.7066ms  cudaFree\n",
      "                    0.99%  20.152ms        10  2.0152ms  7.8680us  19.984ms  cudaLaunchKernel\n",
      "                    0.16%  3.3146ms         1  3.3146ms  3.3146ms  3.3146ms  cudaDeviceSynchronize\n",
      "                    0.02%  506.19us       114  4.4400us     100ns  218.99us  cuDeviceGetAttribute\n",
      "                    0.01%  243.93us         1  243.93us  243.93us  243.93us  cuDeviceGetName\n",
      "                    0.01%  108.28us         1  108.28us  108.28us  108.28us  cudaGetDevice\n",
      "                    0.00%  36.741us         1  36.741us  36.741us  36.741us  cuDeviceGetPCIBusId\n",
      "                    0.00%  26.466us         1  26.466us  26.466us  26.466us  cuDeviceTotalMem\n",
      "                    0.00%  8.1270us         3  2.7090us     112ns  6.5110us  cuDeviceGetCount\n",
      "                    0.00%  5.8810us         2  2.9400us     108ns  5.7730us  cuDeviceGet\n",
      "                    0.00%     945ns         1     945ns     945ns     945ns  cuModuleGetLoadingMode\n",
      "                    0.00%     178ns         1     178ns     178ns     178ns  cuDeviceGetUuid\n",
      "\n",
      "==1031681== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  20.76173ms  Host To Device\n",
      "     128  2.0000MB  2.0000MB  2.0000MB  256.0000MB  229.8112ms  Device To Host\n",
      "Total CPU Page faults: 384\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5373b40-2dbb-40a8-a641-e01f1475922a",
   "metadata": {},
   "source": [
    "# Variant 4.0 - Grid Stride Loop with Prefetch and Page Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "020a7737-1ddb-4031-9e4d-f99222e66b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_var4.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_var4.cu\n",
    "//prefetch + page creation\n",
    "// page creation responsible gpu fault page\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "//CUDA kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "  float *A,*B,*C; \n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, INT_ARRAY_BYTES);\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "//\"prefetch data\" to create CPU page memory\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "//\"prefetch data\" to create GPU page memory\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// ****init array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    A[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "    B[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    "//\"Prefetch data\" from CPU-GPU\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// setup CUDA kernel\n",
    "    size_t numThreads = 1024;   \n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function ***\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks, numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    kernel_C <<<numBlocks, numThreads>>> (ARRAY_SIZE,A,B,C,idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "  //\"Prefetch data\" from GPU-CPU\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "\n",
    "  int sanity_checker = 0;\n",
    "  for (int i = 0; i < ARRAY_SIZE; i++) { \n",
    "        float expected_C = (A[i] >= B[i]) ? A[i] : B[i];\n",
    "        int expected_idx = (A[i] >= B[i]) ? 0 : 1;\n",
    "    \n",
    "        if (fabs(C[i] - expected_C) > 1e-5 || idx[i] != expected_idx) {\n",
    "            sanity_checker++;\n",
    "        }\n",
    "    }\n",
    "  printf(\"Sanity Checker = %d\",sanity_checker);\n",
    "\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(C);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "853e10b1-540f-4ed3-aaa1-15c930185f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var4.cu -o CUDA_var4 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f28773e4-33f5-4f41-bc23-aa056be9ffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1031742== NVPROF is profiling process 1031742, command: ./CUDA_var4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function ***\n",
      "numElements = 16777216\n",
      "numBlocks = 16384, numThreads = 1024 \n",
      "Sanity Checker = 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1031742== Profiling application: ./CUDA_var4\n",
      "==1031742== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  3.6435ms        10  364.35us  361.57us  367.20us  kernel_C(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   82.78%  1.94579s         4  486.45ms  77.617us  1.94460s  cudaMallocManaged\n",
      "                   14.97%  351.87ms        12  29.322ms  24.799us  72.411ms  cudaMemPrefetchAsync\n",
      "                    1.44%  33.910ms         4  8.4776ms  8.2545ms  8.7662ms  cudaFree\n",
      "                    0.62%  14.462ms        10  1.4462ms  12.599us  14.267ms  cudaLaunchKernel\n",
      "                    0.15%  3.5585ms         1  3.5585ms  3.5585ms  3.5585ms  cudaDeviceSynchronize\n",
      "                    0.03%  769.78us       114  6.7520us     133ns  344.23us  cuDeviceGetAttribute\n",
      "                    0.01%  163.05us         1  163.05us  163.05us  163.05us  cuDeviceGetName\n",
      "                    0.00%  28.526us         1  28.526us  28.526us  28.526us  cuDeviceGetPCIBusId\n",
      "                    0.00%  24.818us         1  24.818us  24.818us  24.818us  cuDeviceTotalMem\n",
      "                    0.00%  19.931us         1  19.931us  19.931us  19.931us  cudaGetDevice\n",
      "                    0.00%  15.297us         3  5.0990us     356ns  14.226us  cuDeviceGetCount\n",
      "                    0.00%  9.5980us         2  4.7990us     179ns  9.4190us  cuDeviceGet\n",
      "                    0.00%  1.1870us         1  1.1870us  1.1870us  1.1870us  cuModuleGetLoadingMode\n",
      "                    0.00%     528ns         1     528ns     528ns     528ns  cuDeviceGetUuid\n",
      "\n",
      "==1031742== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  19.37694ms  Host To Device\n",
      "     128  2.0000MB  2.0000MB  2.0000MB  256.0000MB  154.0068ms  Device To Host\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf27c3d-526d-4752-9109-314ead58f1b0",
   "metadata": {},
   "source": [
    "# Variant 5.0 - Grid Stride Loop with Prefetch and Page Creation + mem advise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "164372f7-2a1d-4683-8c52-6607404c7c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_var5.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_var5.cu\n",
    "//prefetch + page creation + memadvise\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "//CUDA kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "  float *A,*B,*C; \n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, INT_ARRAY_BYTES);\n",
    "\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "// memory advise\n",
    "   cudaMemAdvise(A, FLOAT_ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
    "   cudaMemAdvise(A, FLOAT_ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
    "   cudaMemAdvise(B, FLOAT_ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
    "   cudaMemAdvise(B, FLOAT_ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
    "\n",
    "//\"prefetch data\" to create CPU page memory\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "//\"prefetch data\" to create GPU page memory\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// ****init array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    A[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "    B[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    "\n",
    "\n",
    " //\"Prefetch data\" from CPU-GPU\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// setup CUDA kernel\n",
    "    size_t numThreads = 1024;   // what if numThreads>1024, numThreads<1024?\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function ***\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks, numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    kernel_C <<<numBlocks, numThreads>>> (ARRAY_SIZE,A,B,C,idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "  //\"Prefetch data\" from GPU-CPU\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "\n",
    "\n",
    "  int sanity_checker = 0;\n",
    "  for (int i = 0; i < ARRAY_SIZE; i++) { \n",
    "        float expected_C = (A[i] >= B[i]) ? A[i] : B[i];\n",
    "        int expected_idx = (A[i] >= B[i]) ? 0 : 1;\n",
    "    \n",
    "        if (fabs(C[i] - expected_C) > 1e-5 || idx[i] != expected_idx) {\n",
    "            sanity_checker++;\n",
    "        }\n",
    "    }\n",
    "  printf(\"Sanity Checker = %d\",sanity_checker);\n",
    "\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(C);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fd4a82f-8d7e-44ff-a297-f144050f2718",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var5.cu -o CUDA_var5 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19dc4c29-d16f-4529-a1c9-36c8ade23ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1031799== NVPROF is profiling process 1031799, command: ./CUDA_var5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function ***\n",
      "numElements = 16777216\n",
      "numBlocks = 16384, numThreads = 1024 \n",
      "Sanity Checker = 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1031799== Profiling application: ./CUDA_var5\n",
      "==1031799== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  3.6357ms        10  363.57us  361.79us  367.42us  kernel_C(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   84.08%  1.88468s         4  471.17ms  70.095us  1.88343s  cudaMallocManaged\n",
      "                   14.47%  324.33ms        12  27.028ms  240.09us  80.249ms  cudaMemPrefetchAsync\n",
      "                    1.00%  22.419ms         4  5.6047ms  3.4407ms  7.6605ms  cudaFree\n",
      "                    0.15%  3.4218ms        10  342.18us  10.756us  3.1489ms  cudaLaunchKernel\n",
      "                    0.15%  3.3064ms         1  3.3064ms  3.3064ms  3.3064ms  cudaDeviceSynchronize\n",
      "                    0.10%  2.1965ms       114  19.267us     162ns  949.78us  cuDeviceGetAttribute\n",
      "                    0.02%  508.80us         4  127.20us  5.6700us  464.77us  cudaMemAdvise\n",
      "                    0.02%  498.15us         1  498.15us  498.15us  498.15us  cuDeviceGetName\n",
      "                    0.01%  128.75us         1  128.75us  128.75us  128.75us  cuDeviceTotalMem\n",
      "                    0.00%  25.190us         1  25.190us  25.190us  25.190us  cudaGetDevice\n",
      "                    0.00%  24.001us         1  24.001us  24.001us  24.001us  cuDeviceGetPCIBusId\n",
      "                    0.00%  8.3350us         3  2.7780us     136ns  5.2710us  cuDeviceGetCount\n",
      "                    0.00%  6.2800us         2  3.1400us     749ns  5.5310us  cuDeviceGet\n",
      "                    0.00%  2.8520us         1  2.8520us  2.8520us  2.8520us  cuDeviceGetUuid\n",
      "                    0.00%  2.0100us         1  2.0100us  2.0100us  2.0100us  cuModuleGetLoadingMode\n",
      "\n",
      "==1031799== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  19.95213ms  Host To Device\n",
      "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  88.47447ms  Device To Host\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88115767-5ecc-4555-9db7-1ed69bcf01bc",
   "metadata": {},
   "source": [
    "# Variant 6.0 - CUDA classic MEMCPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a4aabf3-01a1-43d9-9ad2-53b22d5623a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_var6.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_var6.cu\n",
    "//grid stride loop + memcpy\n",
    "// BFF PALANG TOH SO FAR + onting research sa websites HJSHAS\n",
    "// UNFINISHED\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "\n",
    "//CUDA kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "\n",
    "float *h_A = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "float *h_B = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "float *h_C = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "int *h_idx = (int*)malloc(INT_ARRAY_BYTES);\n",
    "\n",
    "// ****init host array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    h_A[i] = sinf(i * 0.0005) * 100.0 + 50.0;\n",
    "    h_B[i] = cosf(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    "\n",
    "// device allocations\n",
    "  float *d_A,*d_B,*d_C;\n",
    "  int *d_idx;\n",
    "  cudaMalloc(&d_A, FLOAT_ARRAY_BYTES); //we dont use cudaMallocManaged with cudaMemcpy\n",
    "  cudaMalloc(&d_B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMalloc(&d_C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMalloc(&d_idx, INT_ARRAY_BYTES);\n",
    "\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "// Copy data to device\n",
    "    cudaMemcpy(d_A, h_A, FLOAT_ARRAY_BYTES, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_B, h_B, FLOAT_ARRAY_BYTES, cudaMemcpyHostToDevice);\n",
    "\n",
    "// Kernel launch configuration\n",
    "    int threadsPerBlock = 256;\n",
    "    int blocksPerGrid = (ARRAY_SIZE + threadsPerBlock - 1) / threadsPerBlock;\n",
    "    \n",
    "  for (size_t i=0; i<loope;i++){\n",
    "    kernel_C <<<blocksPerGrid, threadsPerBlock>>> (ARRAY_SIZE, d_A, d_B, d_C, d_idx);\n",
    "    cudaDeviceSynchronize();\n",
    "  }\n",
    "\n",
    "    \n",
    "// Copy results back to host\n",
    "    cudaMemcpy(h_C, d_C, FLOAT_ARRAY_BYTES, cudaMemcpyDeviceToHost);\n",
    "    cudaMemcpy(h_idx, d_idx, INT_ARRAY_BYTES, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Verification loop\n",
    "    int errors = 0;\n",
    "    for (int i = 0; i < ARRAY_SIZE; i++) { \n",
    "        float expected_C = (h_A[i] >= h_B[i]) ? h_A[i] : h_B[i];\n",
    "        int expected_idx = (h_A[i] >= h_B[i]) ? 0 : 1;\n",
    "    \n",
    "        if (fabs(h_C[i] - expected_C) > 1e-5 || h_idx[i] != expected_idx) {\n",
    "            errors++;\n",
    "        }\n",
    "    }\n",
    "    printf(\"Errors = %d\", errors);\n",
    "\n",
    "// Free device memory\n",
    "    cudaFree(d_A);\n",
    "    cudaFree(d_B);\n",
    "    cudaFree(d_C);\n",
    "    cudaFree(d_idx);\n",
    "\n",
    "// Free host memory\n",
    "    free(h_A);\n",
    "    free(h_B);\n",
    "    free(h_C);\n",
    "    free(h_idx);\n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5719731-db6c-40a0-aabf-ebded2ba59e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var6.cu -o CUDA_var6 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a975380-63c1-456d-83cd-cc864431ccd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1031854== NVPROF is profiling process 1031854, command: ./CUDA_var6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors = 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1031854== Profiling application: ./CUDA_var6\n",
      "==1031854== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   81.33%  781.32ms         2  390.66ms  385.76ms  395.56ms  [CUDA memcpy DtoH]\n",
      "                   18.31%  175.87ms         2  87.936ms  83.615ms  92.258ms  [CUDA memcpy HtoD]\n",
      "                    0.36%  3.4481ms        10  344.81us  343.42us  348.35us  kernel_C(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   65.95%  1.93466s         4  483.66ms  1.4087ms  1.92970s  cudaMalloc\n",
      "                   33.55%  984.19ms         4  246.05ms  85.231ms  408.31ms  cudaMemcpy\n",
      "                    0.22%  6.5389ms        10  653.89us  278.12us  3.5259ms  cudaDeviceSynchronize\n",
      "                    0.13%  3.7010ms        10  370.10us  17.592us  2.7638ms  cudaLaunchKernel\n",
      "                    0.11%  3.1907ms         4  797.68us  246.61us  2.2443ms  cudaFree\n",
      "                    0.03%  852.31us       114  7.4760us     141ns  341.41us  cuDeviceGetAttribute\n",
      "                    0.01%  282.05us         1  282.05us  282.05us  282.05us  cuDeviceGetName\n",
      "                    0.00%  140.46us         1  140.46us  140.46us  140.46us  cudaGetDevice\n",
      "                    0.00%  54.690us         1  54.690us  54.690us  54.690us  cuDeviceTotalMem\n",
      "                    0.00%  24.905us         1  24.905us  24.905us  24.905us  cuDeviceGetPCIBusId\n",
      "                    0.00%  11.286us         2  5.6430us  1.0190us  10.267us  cuDeviceGet\n",
      "                    0.00%  5.5220us         3  1.8400us     166ns  5.0890us  cuDeviceGetCount\n",
      "                    0.00%  1.1930us         1  1.1930us  1.1930us  1.1930us  cuModuleGetLoadingMode\n",
      "                    0.00%  1.0300us         1  1.0300us  1.0300us  1.0300us  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10850df-63d3-45ae-b1b1-8bd7dcf330f9",
   "metadata": {},
   "source": [
    "# Variant 7.0 - CUDA init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e06b0940-17a1-4bfa-b1ca-361b75af4e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_var7.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_var7.cu\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "\n",
    "// CUDA kernel to initialize A and B\n",
    "__global__\n",
    "void init_arrays(size_t n, float *A, float *B) {\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride) {\n",
    "        A[i] = sinf(i * 0.0005f) * 100.0f + 50.0f;\n",
    "        B[i] = cosf(i * 0.0003f) * 100.0f + 50.0f;\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    const size_t ARRAY_SIZE = 1 << 24;\n",
    "    const size_t FLOAT_BYTES = ARRAY_SIZE * sizeof(float);\n",
    "\n",
    "    // Unified memory allocation\n",
    "    float *A, *B;\n",
    "    cudaMallocManaged(&A, FLOAT_BYTES);\n",
    "    cudaMallocManaged(&B, FLOAT_BYTES);\n",
    "\n",
    "\n",
    "    // Launch kernel\n",
    "    int threads = 256;\n",
    "    int blocks = (ARRAY_SIZE + threads - 1) / threads;\n",
    "    init_arrays<<<blocks, threads>>>(ARRAY_SIZE, A, B);\n",
    "    cudaDeviceSynchronize();\n",
    "    \n",
    "    // Verification loop (no memcpy needed!)\n",
    "    int error = 0;\n",
    "    for (int i = 0; i < 100; i++) {\n",
    "        float expected_A = sinf(i * 0.0005f) * 100.0f + 50.0f;\n",
    "        float expected_B = cosf(i * 0.0003f) * 100.0f + 50.0f;\n",
    "        if (fabs(A[i] - expected_A) > 1e-4f || fabs(B[i] - expected_B) > 1e-4f) {\n",
    "            error++;\n",
    "        }\n",
    "    }\n",
    "    printf(\"Error = %d\\n\", error);\n",
    "    \n",
    "    // Free unified memory\n",
    "    cudaFree(A);\n",
    "    cudaFree(B);\n",
    "\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1f63e11-88ce-4f2f-8d63-a63773d580ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var7.cu -o CUDA_var7 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2aadaffd-d7ac-4a43-ad1a-f84444e57565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1031909== NVPROF is profiling process 1031909, command: ./CUDA_var7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1031909== Profiling application: ./CUDA_var7\n",
      "==1031909== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  46.889ms         1  46.889ms  46.889ms  46.889ms  init_arrays(unsigned long, float*, float*)\n",
      "      API calls:   97.13%  1.82120s         2  910.60ms  896.45us  1.82030s  cudaMallocManaged\n",
      "                    2.50%  46.945ms         1  46.945ms  46.945ms  46.945ms  cudaDeviceSynchronize\n",
      "                    0.17%  3.1867ms         2  1.5933ms  1.2385ms  1.9481ms  cudaFree\n",
      "                    0.15%  2.8700ms         1  2.8700ms  2.8700ms  2.8700ms  cudaLaunchKernel\n",
      "                    0.03%  585.35us       114  5.1340us     131ns  205.68us  cuDeviceGetAttribute\n",
      "                    0.01%  209.90us         1  209.90us  209.90us  209.90us  cuDeviceGetName\n",
      "                    0.00%  47.214us         1  47.214us  47.214us  47.214us  cuDeviceTotalMem\n",
      "                    0.00%  15.650us         1  15.650us  15.650us  15.650us  cuDeviceGetPCIBusId\n",
      "                    0.00%  12.935us         3  4.3110us     199ns  12.312us  cuDeviceGetCount\n",
      "                    0.00%  6.9810us         1  6.9810us  6.9810us  6.9810us  cuModuleGetLoadingMode\n",
      "                    0.00%  4.8320us         2  2.4160us     366ns  4.4660us  cuDeviceGet\n",
      "                    0.00%     635ns         1     635ns     635ns     635ns  cuDeviceGetUuid\n",
      "\n",
      "==1031909== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "       4  32.000KB  4.0000KB  60.000KB  128.0000KB  63.58300us  Device To Host\n",
      "     190         -         -         -           -  46.62190ms  Gpu page fault groups\n",
      "Total CPU Page faults: 2\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1622c8-d5b5-4d70-aeb2-39c9435ea521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
