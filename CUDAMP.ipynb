{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "675e76ac-3df7-4907-965b-0734ce930776",
   "metadata": {},
   "source": [
    "### Name:\n",
    "> Castillo, Marvien Angel C. <br>\n",
    "> Herrera, Mikhaela Gabrielle B. <br>\n",
    "> Regindin, Sean Adrien I. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ca5222-52aa-4427-9c3b-af43cc723425",
   "metadata": {},
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b62a7b9-a7dd-4fe8-bd35-14496766e694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/bin:/bin:/usr/bin:/usr/local/cuda/bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Add the directory containing the executable to the PATH\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/usr/local/cuda/bin\"\n",
    "\n",
    "# Check if the directory is added to the PATH\n",
    "print(os.environ[\"PATH\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b00f5-9708-40c2-a38d-0c8e34ab5ce7",
   "metadata": {},
   "source": [
    "# Check if CUDA is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "527bdb74-686d-45e2-af5f-ffa4e5722547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2025 NVIDIA Corporation\n",
      "Built on Wed_Apr__9_19:24:57_PDT_2025\n",
      "Cuda compilation tools, release 12.9, V12.9.41\n",
      "Build cuda_12.9.r12.9/compiler.35813241_0\n",
      "nvprof: NVIDIA (R) Cuda command line profiler\n",
      "Copyright (c) 2012 - 2025 NVIDIA Corporation\n",
      "Release version 12.9.19 (21)\n",
      "NVIDIA Nsight Systems version 2025.1.3.140-251335620677v0\n",
      "NVIDIA (R) Nsight Compute Command Line Profiler\n",
      "Copyright (c) 2018-2025 NVIDIA Corporation\n",
      "Version 2025.2.0.0 (build 35613519) (public-release)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvcc --version\n",
    "nvprof --version\n",
    "nsys --version\n",
    "ncu --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d42504cd-6133-426b-8259-bc8b29f494a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov  4 06:55:39 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.51.03              Driver Version: 575.51.03      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           Off |   00000000:00:10.0 Off |                    0 |\n",
      "| N/A   27C    P0             22W /  250W |       0MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d88540-e0ee-436f-bf98-9ca39515d4e7",
   "metadata": {},
   "source": [
    "# Variant 1 - C Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9e971dfd-51ea-442b-9e10-8c56a98da76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C_var1.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile C_var1.c\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "#include <math.h>\n",
    "// ***C function version\n",
    "void kernel_C(float A[], float B[], float C[], size_t n, int idx[]) {\n",
    "\tfor (int i = 0; i < n; i++) {\n",
    "\t\tif (A[i] >= B[i]) {\n",
    "\t\t\tC[i] = A[i];\n",
    "\t\t\tidx[i] = 0;\n",
    "\t\t}\n",
    "\t\telse {\n",
    "\t\t\tC[i] = B[i];\n",
    "\t\t\tidx[i] = 1;\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "int main(int argc, char** argv)\n",
    "{\n",
    "   const size_t ARRAY_SIZE = 1<<24;\n",
    "   const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "   const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    "//number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "   float *C,*A,*B;\n",
    "   int *idx,a;\n",
    "   A = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "   B = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "   C = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "   idx = (int*)malloc(INT_ARRAY_BYTES);\n",
    "   a=2;\n",
    "//timer variables\n",
    "  clock_t start, end;\n",
    "// ***--- initialize your array here ---------\n",
    "   int i;\n",
    "\tfor (i = 0; i < ARRAY_SIZE; i++) {\n",
    "\t\tA[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "\t\tB[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "\t}\n",
    "// fill-in cache\n",
    "    kernel_C(A,B,C,ARRAY_SIZE,idx);\n",
    "//time here\n",
    "  double elapse, time_taken;\n",
    "  elapse = 0.0f;\n",
    "  for (int i=0; i<loope; i++){\n",
    "    start = clock();\n",
    "      kernel_C(A,B,C,ARRAY_SIZE,idx );\n",
    "    end = clock();\n",
    "    time_taken = ((double)(end-start))*1E3/CLOCKS_PER_SEC;\n",
    "    elapse = elapse + time_taken;\n",
    "  }\n",
    "  printf(\"Function (in C) average time for %lu loops is %f milliseconds to execute an array size %lu \\n\", loope, elapse/loope, ARRAY_SIZE);\n",
    "\n",
    "// error checking routine here --\n",
    "   size_t err_count = 0;\n",
    "    for (int i=0; i<ARRAY_SIZE; i++){\n",
    "        if(idx[i] == 0) {\n",
    "            if(C[i] != A[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "        else if (idx[i] == 1) {\n",
    "            if(C[i] != B[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "   printf(\"Error count (C program): %lu\\n\", err_count);\n",
    "  // Free memory\n",
    "  free(A);\n",
    "  free(B);\n",
    "  free(C);\n",
    "  free(idx);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f2937bac-9c8c-4743-8fdc-a70382f397bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcc C_var1.c -o C_var1 -lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c618468c-6a90-48c3-8f9c-2f718297f72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function (in C) average time for 10 loops is 154.756900 milliseconds to execute an array size 16777216 \n",
      "Error count (C program): 0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./C_var1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b7521-df56-4266-b663-02eb5447f81f",
   "metadata": {},
   "source": [
    "# Variant 2 - Grid Stride Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ffa6ecb3-ed9b-4fdd-a509-392a3dc709e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_var2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_var2.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "//Grid stride loop\n",
    "\n",
    "//*** CUDA square kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "  float *A,*B,*C; \n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, INT_ARRAY_BYTES);\n",
    "// *** init array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    A[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "    B[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    "\n",
    "// *** setup CUDA kernel\n",
    "  size_t numThreads = 1024;\n",
    "  size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function = Float kernel_C\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks,numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    kernel_C <<<numBlocks, numThreads>>> (ARRAY_SIZE,A,B,C,idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize();\n",
    "//error checking\n",
    "    size_t err_count = 0;\n",
    "    for (int i=0; i<ARRAY_SIZE; i++){\n",
    "        if(idx[i] == 0) {\n",
    "            if(C[i] != A[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "        else if (idx[i] == 1) {\n",
    "            if(C[i] != B[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "  printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(C);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9c558b99-9904-4214-addc-f54781b834ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var2.cu -o CUDA_var2 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cc02147f-9af0-4a66-82d7-025fb0c4d9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==989565== NVPROF is profiling process 989565, command: ./CUDA_var2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = Float kernel_C\n",
      "numElements = 16777216\n",
      "numBlocks = 16384, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==989565== Profiling application: ./CUDA_var2\n",
      "==989565== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  100.97ms        10  10.097ms  343.74us  97.869ms  kernel_C(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   91.37%  1.26708s         4  316.77ms  41.914us  1.26641s  cudaMallocManaged\n",
      "                    7.28%  100.92ms         1  100.92ms  100.92ms  100.92ms  cudaDeviceSynchronize\n",
      "                    1.17%  16.266ms         4  4.0666ms  3.1726ms  4.7747ms  cudaFree\n",
      "                    0.12%  1.6242ms        10  162.42us  7.8420us  1.4983ms  cudaLaunchKernel\n",
      "                    0.04%  558.32us       114  4.8970us     114ns  214.37us  cuDeviceGetAttribute\n",
      "                    0.01%  200.77us         1  200.77us  200.77us  200.77us  cuDeviceGetName\n",
      "                    0.00%  37.949us         1  37.949us  37.949us  37.949us  cuDeviceTotalMem\n",
      "                    0.00%  8.9970us         1  8.9970us  8.9970us  8.9970us  cuDeviceGetPCIBusId\n",
      "                    0.00%  7.1750us         3  2.3910us     113ns  6.8190us  cuDeviceGetCount\n",
      "                    0.00%  2.6170us         2  1.3080us     155ns  2.4620us  cuDeviceGet\n",
      "                    0.00%     603ns         1     603ns     603ns     603ns  cuModuleGetLoadingMode\n",
      "                    0.00%     333ns         1     333ns     333ns     333ns  cuDeviceGetUuid\n",
      "\n",
      "==989565== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "    5241  25.009KB  4.0000KB  0.9961MB  128.0000MB  38.25932ms  Host To Device\n",
      "    1693  154.84KB  4.0000KB  0.9961MB  256.0000MB  88.99049ms  Device To Host\n",
      "     184         -         -         -           -  97.58996ms  Gpu page fault groups\n",
      "Total CPU Page faults: 1152\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcba6431-ecfa-4d1d-8767-9b07a9110d17",
   "metadata": {},
   "source": [
    "# Variant 3.0 - Grid Stride Loop with Prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d448a7f2-2596-42d1-b7aa-4b6618348517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing CUDA_var3.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_var3.cu\n",
    "// prefetch\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "//CUDA square kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "  float *A,*B,*C; \n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, INT_ARRAY_BYTES);\n",
    "\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "// ****init array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    A[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "    B[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    " //\"Prefetch data\" from CPU-GPU\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// setup CUDA kernel\n",
    "    size_t numThreads = 1024;\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function ***\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks, numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    kernel_C <<<numBlocks, numThreads>>> (ARRAY_SIZE,A,B,C,idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize(); \n",
    "\n",
    "//\"Prefetch data\" from GPU-CPU\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "\n",
    "//error checking\n",
    "    size_t err_count = 0;\n",
    "    for (int i=0; i<ARRAY_SIZE; i++){\n",
    "        if(idx[i] == 0) {\n",
    "            if(C[i] != A[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "        else if (idx[i] == 1) {\n",
    "            if(C[i] != B[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "  printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
    "\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(C);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dcc20dc8-3622-46ec-9924-ae5fb7035e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var3.cu -o CUDA_var3 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2aafe0fd-a19c-4eb8-865b-284ed0604610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==989787== NVPROF is profiling process 989787, command: ./CUDA_var3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function ***\n",
      "numElements = 16777216\n",
      "numBlocks = 16384, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==989787== Profiling application: ./CUDA_var3\n",
      "==989787== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  3.5442ms        10  354.42us  352.61us  358.17us  kernel_C(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   83.27%  554.27ms         4  138.57ms  45.667us  553.88ms  cudaMallocManaged\n",
      "                   11.78%  78.433ms         8  9.8042ms  6.6360us  31.281ms  cudaMemPrefetchAsync\n",
      "                    2.50%  16.653ms         4  4.1633ms  2.4399ms  8.7312ms  cudaFree\n",
      "                    1.86%  12.362ms        10  1.2362ms  4.9500us  12.301ms  cudaLaunchKernel\n",
      "                    0.52%  3.4887ms         1  3.4887ms  3.4887ms  3.4887ms  cudaDeviceSynchronize\n",
      "                    0.05%  308.42us       114  2.7050us     213ns  118.57us  cuDeviceGetAttribute\n",
      "                    0.01%  52.929us         1  52.929us  52.929us  52.929us  cuDeviceGetName\n",
      "                    0.01%  44.551us         1  44.551us  44.551us  44.551us  cuDeviceTotalMem\n",
      "                    0.00%  4.7300us         1  4.7300us  4.7300us  4.7300us  cudaGetDevice\n",
      "                    0.00%  3.0810us         3  1.0270us     290ns  2.4000us  cuDeviceGetCount\n",
      "                    0.00%  2.9210us         1  2.9210us  2.9210us  2.9210us  cuDeviceGetPCIBusId\n",
      "                    0.00%  1.6530us         2     826ns     235ns  1.4180us  cuDeviceGet\n",
      "                    0.00%     479ns         1     479ns     479ns     479ns  cuDeviceGetUuid\n",
      "                    0.00%     334ns         1     334ns     334ns     334ns  cuModuleGetLoadingMode\n",
      "\n",
      "==989787== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  12.42738ms  Host To Device\n",
      "     128  2.0000MB  2.0000MB  2.0000MB  256.0000MB  65.63943ms  Device To Host\n",
      "Total CPU Page faults: 384\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5373b40-2dbb-40a8-a641-e01f1475922a",
   "metadata": {},
   "source": [
    "# Variant 4.0 - Grid Stride Loop with Prefetch and Page Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "020a7737-1ddb-4031-9e4d-f99222e66b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing CUDA_var4.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_var4.cu\n",
    "//prefetch + page creation\n",
    "// page creation responsible gpu fault page\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "//CUDA square kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "  float *A,*B,*C; \n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, INT_ARRAY_BYTES);\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "//\"prefetch data\" to create CPU page memory\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "//\"prefetch data\" to create GPU page memory\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// ****init array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    A[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "    B[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    "//\"Prefetch data\" from CPU-GPU\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// setup CUDA kernel\n",
    "    size_t numThreads = 1024;   \n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function ***\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks, numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    kernel_C <<<numBlocks, numThreads>>> (ARRAY_SIZE,A,B,C,idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "  //\"Prefetch data\" from GPU-CPU\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "\n",
    "//error checking\n",
    "    size_t err_count = 0;\n",
    "    for (int i=0; i<ARRAY_SIZE; i++){\n",
    "        if(idx[i] == 0) {\n",
    "            if(C[i] != A[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "        else if (idx[i] == 1) {\n",
    "            if(C[i] != B[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "  printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
    "\n",
    "\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(C);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "853e10b1-540f-4ed3-aaa1-15c930185f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var4.cu -o CUDA_var4 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f28773e4-33f5-4f41-bc23-aa056be9ffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==989905== NVPROF is profiling process 989905, command: ./CUDA_var4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function ***\n",
      "numElements = 16777216\n",
      "numBlocks = 16384, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==989905== Profiling application: ./CUDA_var4\n",
      "==989905== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  3.6561ms        10  365.61us  362.43us  372.86us  kernel_C(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   77.03%  542.82ms         4  135.70ms  31.108us  542.53ms  cudaMallocManaged\n",
      "                   19.46%  137.11ms        12  11.426ms  15.127us  35.583ms  cudaMemPrefetchAsync\n",
      "                    1.81%  12.746ms        10  1.2746ms  4.6960us  12.685ms  cudaLaunchKernel\n",
      "                    1.12%  7.9101ms         4  1.9775ms  1.8914ms  2.1216ms  cudaFree\n",
      "                    0.51%  3.5987ms         1  3.5987ms  3.5987ms  3.5987ms  cudaDeviceSynchronize\n",
      "                    0.05%  339.91us       114  2.9810us     194ns  139.28us  cuDeviceGetAttribute\n",
      "                    0.01%  56.592us         1  56.592us  56.592us  56.592us  cuDeviceGetName\n",
      "                    0.01%  36.867us         1  36.867us  36.867us  36.867us  cudaGetDevice\n",
      "                    0.00%  33.801us         1  33.801us  33.801us  33.801us  cuDeviceTotalMem\n",
      "                    0.00%  3.8720us         3  1.2900us     201ns  3.1850us  cuDeviceGetCount\n",
      "                    0.00%  3.4990us         1  3.4990us  3.4990us  3.4990us  cuDeviceGetPCIBusId\n",
      "                    0.00%  2.1120us         2  1.0560us     252ns  1.8600us  cuDeviceGet\n",
      "                    0.00%  1.5180us         1  1.5180us  1.5180us  1.5180us  cuDeviceGetUuid\n",
      "                    0.00%     523ns         1     523ns     523ns     523ns  cuModuleGetLoadingMode\n",
      "\n",
      "==989905== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  15.14591ms  Host To Device\n",
      "     128  2.0000MB  2.0000MB  2.0000MB  256.0000MB  83.09843ms  Device To Host\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf27c3d-526d-4752-9109-314ead58f1b0",
   "metadata": {},
   "source": [
    "# Variant 5.0 - Grid Stride Loop with Prefetch and Page Creation + mem advise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "164372f7-2a1d-4683-8c52-6607404c7c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing CUDA_var5.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_var5.cu\n",
    "//prefetch + page creation + memadvise\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "//CUDA square kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "  float *A,*B,*C; \n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, INT_ARRAY_BYTES);\n",
    "\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "// memory advise\n",
    "   cudaMemAdvise(A, FLOAT_ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
    "   cudaMemAdvise(A, FLOAT_ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
    "   cudaMemAdvise(B, FLOAT_ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
    "   cudaMemAdvise(B, FLOAT_ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
    "\n",
    "//\"prefetch data\" to create CPU page memory\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "//\"prefetch data\" to create GPU page memory\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// ****init array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    A[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "    B[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    "\n",
    "\n",
    " //\"Prefetch data\" from CPU-GPU\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// setup CUDA kernel\n",
    "    size_t numThreads = 1024;   // what if numThreads>1024, numThreads<1024?\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function ***\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks, numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    kernel_C <<<numBlocks, numThreads>>> (ARRAY_SIZE,A,B,C,idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "  //\"Prefetch data\" from GPU-CPU\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "\n",
    "//error checking\n",
    "    size_t err_count = 0;\n",
    "    for (int i=0; i<ARRAY_SIZE; i++){\n",
    "        if(idx[i] == 0) {\n",
    "            if(C[i] != A[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "        else if (idx[i] == 1) {\n",
    "            if(C[i] != B[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "  printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
    "\n",
    "\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(C);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd4a82f-8d7e-44ff-a297-f144050f2718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
