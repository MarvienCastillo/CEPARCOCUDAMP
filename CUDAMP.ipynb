{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "675e76ac-3df7-4907-965b-0734ce930776",
   "metadata": {},
   "source": [
    "### Name:\n",
    "> Castillo, Marvien Angel C. <br>\n",
    "> Herrera, Mikhaela Gabrielle B. <br>\n",
    "> Regindin, Sean Adrien I. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ca5222-52aa-4427-9c3b-af43cc723425",
   "metadata": {},
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b62a7b9-a7dd-4fe8-bd35-14496766e694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/bin:/bin:/usr/bin:/usr/local/cuda/bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Add the directory containing the executable to the PATH\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/usr/local/cuda/bin\"\n",
    "\n",
    "# Check if the directory is added to the PATH\n",
    "print(os.environ[\"PATH\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b00f5-9708-40c2-a38d-0c8e34ab5ce7",
   "metadata": {},
   "source": [
    "# Check if CUDA is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "527bdb74-686d-45e2-af5f-ffa4e5722547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2025 NVIDIA Corporation\n",
      "Built on Wed_Apr__9_19:24:57_PDT_2025\n",
      "Cuda compilation tools, release 12.9, V12.9.41\n",
      "Build cuda_12.9.r12.9/compiler.35813241_0\n",
      "nvprof: NVIDIA (R) Cuda command line profiler\n",
      "Copyright (c) 2012 - 2025 NVIDIA Corporation\n",
      "Release version 12.9.19 (21)\n",
      "NVIDIA Nsight Systems version 2025.1.3.140-251335620677v0\n",
      "NVIDIA (R) Nsight Compute Command Line Profiler\n",
      "Copyright (c) 2018-2025 NVIDIA Corporation\n",
      "Version 2025.2.0.0 (build 35613519) (public-release)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvcc --version\n",
    "nvprof --version\n",
    "nsys --version\n",
    "ncu --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d42504cd-6133-426b-8259-bc8b29f494a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov  6 06:01:50 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.51.03              Driver Version: 575.51.03      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           Off |   00000000:00:10.0 Off |                    0 |\n",
      "| N/A   27C    P0             22W /  250W |       0MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d88540-e0ee-436f-bf98-9ca39515d4e7",
   "metadata": {},
   "source": [
    "# Variant 1 - C Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e971dfd-51ea-442b-9e10-8c56a98da76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting C_var1.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile C_var1.c\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "#include <math.h>\n",
    "// ***C function version\n",
    "void kernel_C(float A[], float B[], float C[], size_t n, int idx[]) {\n",
    "\tfor (int i = 0; i < n; i++) {\n",
    "\t\tif (A[i] >= B[i]) {\n",
    "\t\t\tC[i] = A[i];\n",
    "\t\t\tidx[i] = 0;\n",
    "\t\t}\n",
    "\t\telse {\n",
    "\t\t\tC[i] = B[i];\n",
    "\t\t\tidx[i] = 1;\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "int main(int argc, char** argv)\n",
    "{\n",
    "   const size_t ARRAY_SIZE = 1<<24;\n",
    "   const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "   const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    "//number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "   float *C,*A,*B;\n",
    "   int *idx,a;\n",
    "   A = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "   B = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "   C = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "   idx = (int*)malloc(INT_ARRAY_BYTES);\n",
    "   a=2;\n",
    "//timer variables\n",
    "  clock_t start, end;\n",
    "// ***--- initialize your array here ---------\n",
    "   int i;\n",
    "\tfor (i = 0; i < ARRAY_SIZE; i++) {\n",
    "\t\tA[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "\t\tB[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "\t}\n",
    "// fill-in cache\n",
    "    kernel_C(A,B,C,ARRAY_SIZE,idx);\n",
    "//time here\n",
    "  double elapse, time_taken;\n",
    "  elapse = 0.0f;\n",
    "  for (int i=0; i<loope; i++){\n",
    "    start = clock();\n",
    "      kernel_C(A,B,C,ARRAY_SIZE,idx );\n",
    "    end = clock();\n",
    "    time_taken = ((double)(end-start))*1E3/CLOCKS_PER_SEC;\n",
    "    elapse = elapse + time_taken;\n",
    "  }\n",
    "  printf(\"Function (in C) average time for %lu loops is %f milliseconds to execute an array size %lu \\n\", loope, elapse/loope, ARRAY_SIZE);\n",
    "\n",
    "// error checking routine here --\n",
    "   size_t err_count = 0;\n",
    "    for (int i=0; i<ARRAY_SIZE; i++){\n",
    "        if(idx[i] == 0) {\n",
    "            if(C[i] != A[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "        else if (idx[i] == 1) {\n",
    "            if(C[i] != B[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "   printf(\"Error count (C program): %lu\\n\", err_count);\n",
    "  // Free memory\n",
    "  free(A);\n",
    "  free(B);\n",
    "  free(C);\n",
    "  free(idx);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2937bac-9c8c-4743-8fdc-a70382f397bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcc C_var1.c -o C_var1 -lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c618468c-6a90-48c3-8f9c-2f718297f72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function (in C) average time for 10 loops is 241.238400 milliseconds to execute an array size 16777216 \n",
      "Error count (C program): 0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./C_var1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b7521-df56-4266-b663-02eb5447f81f",
   "metadata": {},
   "source": [
    "# Variant 2 - Grid Stride Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffa6ecb3-ed9b-4fdd-a509-392a3dc709e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_var2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_var2.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "//Grid stride loop\n",
    "\n",
    "//*** CUDA kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "  float *A,*B,*C; \n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, INT_ARRAY_BYTES);\n",
    "// *** init array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    A[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "    B[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    "\n",
    "// *** setup CUDA kernel\n",
    "  size_t numThreads = 1024;\n",
    "  size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function = Float kernel_C\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks,numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    kernel_C <<<numBlocks, numThreads>>> (ARRAY_SIZE,A,B,C,idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize();\n",
    "//error checking\n",
    "    size_t err_count = 0;\n",
    "    for (int i=0; i<ARRAY_SIZE; i++){\n",
    "        if(idx[i] == 0) {\n",
    "            if(C[i] != A[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "        else if (idx[i] == 1) {\n",
    "            if(C[i] != B[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "  printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(C);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c558b99-9904-4214-addc-f54781b834ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var2.cu -o CUDA_var2 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc02147f-9af0-4a66-82d7-025fb0c4d9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1024212== NVPROF is profiling process 1024212, command: ./CUDA_var2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = Float kernel_C\n",
      "numElements = 16777216\n",
      "numBlocks = 16384, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1024212== Profiling application: ./CUDA_var2\n",
      "==1024212== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  104.62ms        10  10.462ms  343.84us  101.52ms  kernel_C(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   91.47%  1.46767s         4  366.92ms  49.380us  1.46663s  cudaMallocManaged\n",
      "                    6.51%  104.52ms         1  104.52ms  104.52ms  104.52ms  cudaDeviceSynchronize\n",
      "                    1.82%  29.226ms         4  7.3065ms  6.2992ms  9.2770ms  cudaFree\n",
      "                    0.15%  2.3799ms        10  237.99us  9.3640us  2.2190ms  cudaLaunchKernel\n",
      "                    0.03%  463.40us       114  4.0640us     114ns  204.80us  cuDeviceGetAttribute\n",
      "                    0.01%  192.44us         1  192.44us  192.44us  192.44us  cuDeviceGetName\n",
      "                    0.00%  38.228us         1  38.228us  38.228us  38.228us  cuDeviceTotalMem\n",
      "                    0.00%  14.452us         1  14.452us  14.452us  14.452us  cuDeviceGetPCIBusId\n",
      "                    0.00%  9.6670us         3  3.2220us     159ns  9.1870us  cuDeviceGetCount\n",
      "                    0.00%  6.0750us         2  3.0370us     157ns  5.9180us  cuDeviceGet\n",
      "                    0.00%     664ns         1     664ns     664ns     664ns  cuModuleGetLoadingMode\n",
      "                    0.00%     216ns         1     216ns     216ns     216ns  cuDeviceGetUuid\n",
      "\n",
      "==1024212== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "    5335  24.567KB  4.0000KB  0.9961MB  128.0000MB  43.13603ms  Host To Device\n",
      "    1693  154.84KB  4.0000KB  0.9961MB  256.0000MB  102.7523ms  Device To Host\n",
      "     188         -         -         -           -  101.2375ms  Gpu page fault groups\n",
      "Total CPU Page faults: 1152\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcba6431-ecfa-4d1d-8767-9b07a9110d17",
   "metadata": {},
   "source": [
    "# Variant 3.0 - Grid Stride Loop with Prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d448a7f2-2596-42d1-b7aa-4b6618348517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_var3.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_var3.cu\n",
    "// prefetch\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "//CUDA kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "  float *A,*B,*C; \n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, INT_ARRAY_BYTES);\n",
    "\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "// ****init array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    A[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "    B[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    " //\"Prefetch data\" from CPU-GPU\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// setup CUDA kernel\n",
    "    size_t numThreads = 1024;\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function ***\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks, numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    kernel_C <<<numBlocks, numThreads>>> (ARRAY_SIZE,A,B,C,idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize(); \n",
    "\n",
    "//\"Prefetch data\" from GPU-CPU\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "\n",
    "//error checking\n",
    "    size_t err_count = 0;\n",
    "    for (int i=0; i<ARRAY_SIZE; i++){\n",
    "        if(idx[i] == 0) {\n",
    "            if(C[i] != A[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "        else if (idx[i] == 1) {\n",
    "            if(C[i] != B[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "  printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
    "\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(C);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcc20dc8-3622-46ec-9924-ae5fb7035e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var3.cu -o CUDA_var3 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2aafe0fd-a19c-4eb8-865b-284ed0604610",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1024270== NVPROF is profiling process 1024270, command: ./CUDA_var3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function ***\n",
      "numElements = 16777216\n",
      "numBlocks = 16384, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1024270== Profiling application: ./CUDA_var3\n",
      "==1024270== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  3.5445ms        10  354.45us  350.24us  359.36us  kernel_C(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   86.79%  1.14978s         4  287.45ms  68.581us  1.14878s  cudaMallocManaged\n",
      "                   10.33%  136.83ms         8  17.104ms  15.562us  44.159ms  cudaMemPrefetchAsync\n",
      "                    1.37%  18.107ms         4  4.5267ms  3.5474ms  5.4832ms  cudaFree\n",
      "                    1.21%  15.976ms        10  1.5976ms  9.3090us  15.825ms  cudaLaunchKernel\n",
      "                    0.25%  3.3265ms         1  3.3265ms  3.3265ms  3.3265ms  cudaDeviceSynchronize\n",
      "                    0.04%  498.20us       114  4.3700us     139ns  194.46us  cuDeviceGetAttribute\n",
      "                    0.02%  206.83us         1  206.83us  206.83us  206.83us  cuDeviceGetName\n",
      "                    0.01%  70.355us         1  70.355us  70.355us  70.355us  cuDeviceTotalMem\n",
      "                    0.00%  18.341us         1  18.341us  18.341us  18.341us  cudaGetDevice\n",
      "                    0.00%  17.676us         1  17.676us  17.676us  17.676us  cuDeviceGetPCIBusId\n",
      "                    0.00%  3.7340us         3  1.2440us     216ns  3.1700us  cuDeviceGetCount\n",
      "                    0.00%  3.4500us         2  1.7250us     273ns  3.1770us  cuDeviceGet\n",
      "                    0.00%  1.2860us         1  1.2860us  1.2860us  1.2860us  cuDeviceGetUuid\n",
      "                    0.00%     516ns         1     516ns     516ns     516ns  cuModuleGetLoadingMode\n",
      "\n",
      "==1024270== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  17.60033ms  Host To Device\n",
      "     128  2.0000MB  2.0000MB  2.0000MB  256.0000MB  110.7886ms  Device To Host\n",
      "Total CPU Page faults: 384\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5373b40-2dbb-40a8-a641-e01f1475922a",
   "metadata": {},
   "source": [
    "# Variant 4.0 - Grid Stride Loop with Prefetch and Page Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "020a7737-1ddb-4031-9e4d-f99222e66b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_var4.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_var4.cu\n",
    "//prefetch + page creation\n",
    "// page creation responsible gpu fault page\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "//CUDA kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "  float *A,*B,*C; \n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, INT_ARRAY_BYTES);\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "//\"prefetch data\" to create CPU page memory\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "//\"prefetch data\" to create GPU page memory\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// ****init array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    A[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "    B[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    "//\"Prefetch data\" from CPU-GPU\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// setup CUDA kernel\n",
    "    size_t numThreads = 1024;   \n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function ***\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks, numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    kernel_C <<<numBlocks, numThreads>>> (ARRAY_SIZE,A,B,C,idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "  //\"Prefetch data\" from GPU-CPU\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "\n",
    "//error checking\n",
    "    size_t err_count = 0;\n",
    "    for (int i=0; i<ARRAY_SIZE; i++){\n",
    "        if(idx[i] == 0) {\n",
    "            if(C[i] != A[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "        else if (idx[i] == 1) {\n",
    "            if(C[i] != B[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "  printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
    "\n",
    "\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(C);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "853e10b1-540f-4ed3-aaa1-15c930185f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var4.cu -o CUDA_var4 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f28773e4-33f5-4f41-bc23-aa056be9ffa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1024327== NVPROF is profiling process 1024327, command: ./CUDA_var4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function ***\n",
      "numElements = 16777216\n",
      "numBlocks = 16384, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1024327== Profiling application: ./CUDA_var4\n",
      "==1024327== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  3.6407ms        10  364.07us  362.27us  369.63us  kernel_C(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   71.86%  1.12144s         4  280.36ms  79.531us  1.12039s  cudaMallocManaged\n",
      "                   25.56%  398.93ms        12  33.244ms  18.953us  96.565ms  cudaMemPrefetchAsync\n",
      "                    1.28%  19.922ms         4  4.9805ms  4.5466ms  5.3526ms  cudaFree\n",
      "                    1.01%  15.815ms        10  1.5815ms  7.2500us  15.642ms  cudaLaunchKernel\n",
      "                    0.22%  3.4303ms         1  3.4303ms  3.4303ms  3.4303ms  cudaDeviceSynchronize\n",
      "                    0.04%  643.68us       114  5.6460us     102ns  267.05us  cuDeviceGetAttribute\n",
      "                    0.01%  205.81us         1  205.81us  205.81us  205.81us  cuDeviceGetName\n",
      "                    0.00%  62.119us         1  62.119us  62.119us  62.119us  cuDeviceTotalMem\n",
      "                    0.00%  17.143us         1  17.143us  17.143us  17.143us  cuDeviceGetPCIBusId\n",
      "                    0.00%  13.610us         1  13.610us  13.610us  13.610us  cudaGetDevice\n",
      "                    0.00%  9.3030us         3  3.1010us     106ns  8.9380us  cuDeviceGetCount\n",
      "                    0.00%  6.2760us         2  3.1380us     190ns  6.0860us  cuDeviceGet\n",
      "                    0.00%  1.0610us         1  1.0610us  1.0610us  1.0610us  cuDeviceGetUuid\n",
      "                    0.00%     813ns         1     813ns     813ns     813ns  cuModuleGetLoadingMode\n",
      "\n",
      "==1024327== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  19.49365ms  Host To Device\n",
      "     128  2.0000MB  2.0000MB  2.0000MB  256.0000MB  84.17510ms  Device To Host\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf27c3d-526d-4752-9109-314ead58f1b0",
   "metadata": {},
   "source": [
    "# Variant 5.0 - Grid Stride Loop with Prefetch and Page Creation + mem advise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "164372f7-2a1d-4683-8c52-6607404c7c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_var5.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_var5.cu\n",
    "//prefetch + page creation + memadvise\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "//CUDA kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "  float *A,*B,*C; \n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, INT_ARRAY_BYTES);\n",
    "\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "// memory advise\n",
    "   cudaMemAdvise(A, FLOAT_ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
    "   cudaMemAdvise(A, FLOAT_ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
    "   cudaMemAdvise(B, FLOAT_ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
    "   cudaMemAdvise(B, FLOAT_ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
    "\n",
    "//\"prefetch data\" to create CPU page memory\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "//\"prefetch data\" to create GPU page memory\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// ****init array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    A[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "    B[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    "\n",
    "\n",
    " //\"Prefetch data\" from CPU-GPU\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// setup CUDA kernel\n",
    "    size_t numThreads = 1024;   // what if numThreads>1024, numThreads<1024?\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function ***\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks, numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    kernel_C <<<numBlocks, numThreads>>> (ARRAY_SIZE,A,B,C,idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "  //\"Prefetch data\" from GPU-CPU\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "\n",
    "//error checking\n",
    "    size_t err_count = 0;\n",
    "    for (int i=0; i<ARRAY_SIZE; i++){\n",
    "        if(idx[i] == 0) {\n",
    "            if(C[i] != A[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "        else if (idx[i] == 1) {\n",
    "            if(C[i] != B[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "  printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
    "\n",
    "\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(C);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fd4a82f-8d7e-44ff-a297-f144050f2718",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var5.cu -o CUDA_var5 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19dc4c29-d16f-4529-a1c9-36c8ade23ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1024382== NVPROF is profiling process 1024382, command: ./CUDA_var5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function ***\n",
      "numElements = 16777216\n",
      "numBlocks = 16384, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1024382== Profiling application: ./CUDA_var5\n",
      "==1024382== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  3.6437ms        10  364.37us  361.25us  367.97us  kernel_C(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   80.48%  1.21016s         4  302.54ms  44.046us  1.20924s  cudaMallocManaged\n",
      "                   17.68%  265.87ms        12  22.156ms  208.66us  75.676ms  cudaMemPrefetchAsync\n",
      "                    1.38%  20.735ms         4  5.1838ms  3.7294ms  6.4861ms  cudaFree\n",
      "                    0.23%  3.4470ms         1  3.4470ms  3.4470ms  3.4470ms  cudaDeviceSynchronize\n",
      "                    0.15%  2.2501ms        10  225.01us  17.314us  2.0426ms  cudaLaunchKernel\n",
      "                    0.05%  741.70us       114  6.5060us     180ns  343.44us  cuDeviceGetAttribute\n",
      "                    0.01%  186.23us         1  186.23us  186.23us  186.23us  cuDeviceGetName\n",
      "                    0.01%  108.79us         4  27.197us  7.0760us  83.259us  cudaMemAdvise\n",
      "                    0.00%  64.578us         1  64.578us  64.578us  64.578us  cuDeviceTotalMem\n",
      "                    0.00%  23.466us         1  23.466us  23.466us  23.466us  cuDeviceGetPCIBusId\n",
      "                    0.00%  11.839us         3  3.9460us     242ns  10.801us  cuDeviceGetCount\n",
      "                    0.00%  10.591us         2  5.2950us     311ns  10.280us  cuDeviceGet\n",
      "                    0.00%  9.9000us         1  9.9000us  9.9000us  9.9000us  cudaGetDevice\n",
      "                    0.00%     586ns         1     586ns     586ns     586ns  cuModuleGetLoadingMode\n",
      "                    0.00%     473ns         1     473ns     473ns     473ns  cuDeviceGetUuid\n",
      "\n",
      "==1024382== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  17.28520ms  Host To Device\n",
      "      64  2.0000MB  2.0000MB  2.0000MB  128.0000MB  89.28039ms  Device To Host\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88115767-5ecc-4555-9db7-1ed69bcf01bc",
   "metadata": {},
   "source": [
    "# Variant 6.0 - CUDA classic MEMCPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a4aabf3-01a1-43d9-9ad2-53b22d5623a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting CUDA_var6.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_var6.cu\n",
    "//grid stride loop + memcpy\n",
    "// BFF PALANG TOH SO FAR + onting research sa websites HJSHAS\n",
    "// UNFINISHED\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "\n",
    "//CUDA kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "\n",
    "float *h_A = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "float *h_B = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "float *h_C = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "int *h_idx = (int*)malloc(INT_ARRAY_BYTES);\n",
    "\n",
    "// ****init host array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    h_A[i] = sinf(i * 0.0005) * 100.0 + 50.0;\n",
    "    h_B[i] = cosf(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    "\n",
    "// device allocations\n",
    "  float *d_A,*d_B,*d_C;\n",
    "  int *d_idx;\n",
    "  cudaMalloc(&d_A, FLOAT_ARRAY_BYTES); //we dont use cudaMallocManaged with cudaMemcpy\n",
    "  cudaMalloc(&d_B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMalloc(&d_C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMalloc(&d_idx, INT_ARRAY_BYTES);\n",
    "\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "// Copy data to device\n",
    "    cudaMemcpy(d_A, h_A, FLOAT_ARRAY_BYTES, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_B, h_B, FLOAT_ARRAY_BYTES, cudaMemcpyHostToDevice);\n",
    "\n",
    "// Kernel launch configuration\n",
    "    int threadsPerBlock = 256;\n",
    "    int blocksPerGrid = (ARRAY_SIZE + threadsPerBlock - 1) / threadsPerBlock;\n",
    "    \n",
    "  for (size_t i=0; i<loope;i++){\n",
    "    kernel_C <<<blocksPerGrid, threadsPerBlock>>> (ARRAY_SIZE, d_A, d_B, d_C, d_idx);\n",
    "    cudaDeviceSynchronize();\n",
    "  }\n",
    "\n",
    "    \n",
    "// Copy results back to host\n",
    "    cudaMemcpy(h_C, d_C, FLOAT_ARRAY_BYTES, cudaMemcpyDeviceToHost);\n",
    "    cudaMemcpy(h_idx, d_idx, INT_ARRAY_BYTES, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // Verification loop\n",
    "    int errors = 0;\n",
    "    for (int i = 0; i < 100; i++) { // Check first 100 elements for brevity\n",
    "        float expected_C = (h_A[i] >= h_B[i]) ? h_A[i] : h_B[i];\n",
    "        int expected_idx = (h_A[i] >= h_B[i]) ? 0 : 1;\n",
    "    \n",
    "        if (fabs(h_C[i] - expected_C) > 1e-5 || h_idx[i] != expected_idx) {\n",
    "            errors++;\n",
    "        }\n",
    "    }\n",
    "    printf(\"Errors = %d\", errors);\n",
    "\n",
    "// Free device memory\n",
    "    cudaFree(d_A);\n",
    "    cudaFree(d_B);\n",
    "    cudaFree(d_C);\n",
    "    cudaFree(d_idx);\n",
    "\n",
    "// Free host memory\n",
    "    free(h_A);\n",
    "    free(h_B);\n",
    "    free(h_C);\n",
    "    free(h_idx);\n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a5719731-db6c-40a0-aabf-ebded2ba59e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var6.cu -o CUDA_var6 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82fb784d-b5ec-4cc1-b9f6-ae8ee8c4b303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors = 0"
     ]
    }
   ],
   "source": [
    "!./CUDA_var6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a975380-63c1-456d-83cd-cc864431ccd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1025053== NVPROF is profiling process 1025053, command: ./CUDA_var6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors = 0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1025053== Profiling application: ./CUDA_var6\n",
      "==1025053== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:   82.84%  766.84ms         2  383.42ms  373.85ms  392.99ms  [CUDA memcpy DtoH]\n",
      "                   16.78%  155.37ms         2  77.686ms  75.024ms  80.349ms  [CUDA memcpy HtoD]\n",
      "                    0.37%  3.4546ms        10  345.46us  343.93us  349.44us  kernel_C(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   60.27%  1.45820s         4  364.55ms  175.02us  1.45738s  cudaMalloc\n",
      "                   39.20%  948.55ms         4  237.14ms  76.280ms  404.40ms  cudaMemcpy\n",
      "                    0.18%  4.3068ms       114  37.778us     103ns  3.5793ms  cuDeviceGetAttribute\n",
      "                    0.15%  3.5939ms        10  359.39us  302.02us  484.38us  cudaDeviceSynchronize\n",
      "                    0.10%  2.4618ms         4  615.45us  207.75us  1.5057ms  cudaFree\n",
      "                    0.08%  2.0030ms        10  200.30us  16.304us  1.8005ms  cudaLaunchKernel\n",
      "                    0.01%  310.89us         1  310.89us  310.89us  310.89us  cuDeviceGetName\n",
      "                    0.00%  55.274us         1  55.274us  55.274us  55.274us  cuDeviceTotalMem\n",
      "                    0.00%  28.740us         1  28.740us  28.740us  28.740us  cuDeviceGetPCIBusId\n",
      "                    0.00%  10.625us         3  3.5410us     113ns  8.8740us  cuDeviceGetCount\n",
      "                    0.00%  8.2710us         1  8.2710us  8.2710us  8.2710us  cudaGetDevice\n",
      "                    0.00%  3.2790us         2  1.6390us     124ns  3.1550us  cuDeviceGet\n",
      "                    0.00%  2.3360us         1  2.3360us  2.3360us  2.3360us  cuModuleGetLoadingMode\n",
      "                    0.00%  1.3810us         1  1.3810us  1.3810us  1.3810us  cuDeviceGetUuid\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d35ab59-801c-4a6b-a164-3373f33cfaed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
