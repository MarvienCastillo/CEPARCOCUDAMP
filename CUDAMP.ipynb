{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "675e76ac-3df7-4907-965b-0734ce930776",
   "metadata": {},
   "source": [
    "### Name:\n",
    "> Castillo, Marvien Angel C. <br>\n",
    "> Herrera, Mikhaela Gabrielle B. <br>\n",
    "> Regindin, Sean Adrien I. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ca5222-52aa-4427-9c3b-af43cc723425",
   "metadata": {},
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b62a7b9-a7dd-4fe8-bd35-14496766e694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/bin:/bin:/usr/bin:/usr/local/cuda/bin\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Add the directory containing the executable to the PATH\n",
    "os.environ[\"PATH\"] += os.pathsep + \"/usr/local/cuda/bin\"\n",
    "\n",
    "# Check if the directory is added to the PATH\n",
    "print(os.environ[\"PATH\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0b00f5-9708-40c2-a38d-0c8e34ab5ce7",
   "metadata": {},
   "source": [
    "# Check if CUDA is present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "527bdb74-686d-45e2-af5f-ffa4e5722547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2025 NVIDIA Corporation\n",
      "Built on Wed_Apr__9_19:24:57_PDT_2025\n",
      "Cuda compilation tools, release 12.9, V12.9.41\n",
      "Build cuda_12.9.r12.9/compiler.35813241_0\n",
      "nvprof: NVIDIA (R) Cuda command line profiler\n",
      "Copyright (c) 2012 - 2025 NVIDIA Corporation\n",
      "Release version 12.9.19 (21)\n",
      "NVIDIA Nsight Systems version 2025.1.3.140-251335620677v0\n",
      "NVIDIA (R) Nsight Compute Command Line Profiler\n",
      "Copyright (c) 2018-2025 NVIDIA Corporation\n",
      "Version 2025.2.0.0 (build 35613519) (public-release)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvcc --version\n",
    "nvprof --version\n",
    "nsys --version\n",
    "ncu --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d42504cd-6133-426b-8259-bc8b29f494a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov  6 03:26:45 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.51.03              Driver Version: 575.51.03      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla V100-PCIE-32GB           Off |   00000000:00:10.0 Off |                    0 |\n",
      "| N/A   28C    P0             22W /  250W |       0MiB /  32768MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d88540-e0ee-436f-bf98-9ca39515d4e7",
   "metadata": {},
   "source": [
    "# Variant 1 - C Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e971dfd-51ea-442b-9e10-8c56a98da76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing C_var1.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile C_var1.c\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <time.h>\n",
    "#include <math.h>\n",
    "// ***C function version\n",
    "void kernel_C(float A[], float B[], float C[], size_t n, int idx[]) {\n",
    "\tfor (int i = 0; i < n; i++) {\n",
    "\t\tif (A[i] >= B[i]) {\n",
    "\t\t\tC[i] = A[i];\n",
    "\t\t\tidx[i] = 0;\n",
    "\t\t}\n",
    "\t\telse {\n",
    "\t\t\tC[i] = B[i];\n",
    "\t\t\tidx[i] = 1;\n",
    "\t\t}\n",
    "\t}\n",
    "}\n",
    "\n",
    "int main(int argc, char** argv)\n",
    "{\n",
    "   const size_t ARRAY_SIZE = 1<<24;\n",
    "   const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "   const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    "//number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "   float *C,*A,*B;\n",
    "   int *idx,a;\n",
    "   A = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "   B = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "   C = (float*)malloc(FLOAT_ARRAY_BYTES);\n",
    "   idx = (int*)malloc(INT_ARRAY_BYTES);\n",
    "   a=2;\n",
    "//timer variables\n",
    "  clock_t start, end;\n",
    "// ***--- initialize your array here ---------\n",
    "   int i;\n",
    "\tfor (i = 0; i < ARRAY_SIZE; i++) {\n",
    "\t\tA[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "\t\tB[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "\t}\n",
    "// fill-in cache\n",
    "    kernel_C(A,B,C,ARRAY_SIZE,idx);\n",
    "//time here\n",
    "  double elapse, time_taken;\n",
    "  elapse = 0.0f;\n",
    "  for (int i=0; i<loope; i++){\n",
    "    start = clock();\n",
    "      kernel_C(A,B,C,ARRAY_SIZE,idx );\n",
    "    end = clock();\n",
    "    time_taken = ((double)(end-start))*1E3/CLOCKS_PER_SEC;\n",
    "    elapse = elapse + time_taken;\n",
    "  }\n",
    "  printf(\"Function (in C) average time for %lu loops is %f milliseconds to execute an array size %lu \\n\", loope, elapse/loope, ARRAY_SIZE);\n",
    "\n",
    "// error checking routine here --\n",
    "   size_t err_count = 0;\n",
    "    for (int i=0; i<ARRAY_SIZE; i++){\n",
    "        if(idx[i] == 0) {\n",
    "            if(C[i] != A[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "        else if (idx[i] == 1) {\n",
    "            if(C[i] != B[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "   printf(\"Error count (C program): %lu\\n\", err_count);\n",
    "  // Free memory\n",
    "  free(A);\n",
    "  free(B);\n",
    "  free(C);\n",
    "  free(idx);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2937bac-9c8c-4743-8fdc-a70382f397bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "gcc C_var1.c -o C_var1 -lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c618468c-6a90-48c3-8f9c-2f718297f72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function (in C) average time for 10 loops is 259.889500 milliseconds to execute an array size 16777216 \n",
      "Error count (C program): 0\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./C_var1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3b7521-df56-4266-b663-02eb5447f81f",
   "metadata": {},
   "source": [
    "# Variant 2 - Grid Stride Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffa6ecb3-ed9b-4fdd-a509-392a3dc709e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing CUDA_var2.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile CUDA_var2.cu\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <math.h>\n",
    "//Grid stride loop\n",
    "\n",
    "//*** CUDA kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "  float *A,*B,*C; \n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, INT_ARRAY_BYTES);\n",
    "// *** init array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    A[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "    B[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    "\n",
    "// *** setup CUDA kernel\n",
    "  size_t numThreads = 1024;\n",
    "  size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function = Float kernel_C\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks,numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    kernel_C <<<numBlocks, numThreads>>> (ARRAY_SIZE,A,B,C,idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize();\n",
    "//error checking\n",
    "    size_t err_count = 0;\n",
    "    for (int i=0; i<ARRAY_SIZE; i++){\n",
    "        if(idx[i] == 0) {\n",
    "            if(C[i] != A[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "        else if (idx[i] == 1) {\n",
    "            if(C[i] != B[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "  printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(C);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c558b99-9904-4214-addc-f54781b834ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var2.cu -o CUDA_var2 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc02147f-9af0-4a66-82d7-025fb0c4d9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1018580== NVPROF is profiling process 1018580, command: ./CUDA_var2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** function = Float kernel_C\n",
      "numElements = 16777216\n",
      "numBlocks = 16384, numThreads = 1024 \n",
      "Error count(CUDA program): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==1018580== Profiling application: ./CUDA_var2\n",
      "==1018580== Profiling result:\n",
      "            Type  Time(%)      Time     Calls       Avg       Min       Max  Name\n",
      " GPU activities:  100.00%  122.76ms        10  12.276ms  343.45us  119.66ms  kernel_C(unsigned long, float*, float*, float*, int*)\n",
      "      API calls:   87.47%  1.62461s         4  406.15ms  81.704us  1.62331s  cudaMallocManaged\n",
      "                    6.60%  122.51ms         1  122.51ms  122.51ms  122.51ms  cudaDeviceSynchronize\n",
      "                    4.22%  78.463ms        10  7.8463ms  14.638us  78.113ms  cudaLaunchKernel\n",
      "                    1.57%  29.234ms         4  7.3084ms  6.8059ms  8.1321ms  cudaFree\n",
      "                    0.12%  2.1992ms       114  19.290us     127ns  1.6766ms  cuDeviceGetAttribute\n",
      "                    0.01%  130.80us         1  130.80us  130.80us  130.80us  cuDeviceGetName\n",
      "                    0.00%  64.217us         1  64.217us  64.217us  64.217us  cuDeviceGetPCIBusId\n",
      "                    0.00%  31.000us         1  31.000us  31.000us  31.000us  cuDeviceTotalMem\n",
      "                    0.00%  8.3120us         3  2.7700us     296ns  6.5410us  cuDeviceGetCount\n",
      "                    0.00%  6.9330us         2  3.4660us     706ns  6.2270us  cuDeviceGet\n",
      "                    0.00%  2.3210us         1  2.3210us  2.3210us  2.3210us  cuDeviceGetUuid\n",
      "                    0.00%     697ns         1     697ns     697ns     697ns  cuModuleGetLoadingMode\n",
      "\n",
      "==1018580== Unified Memory profiling result:\n",
      "Device \"Tesla V100-PCIE-32GB (0)\"\n",
      "   Count  Avg Size  Min Size  Max Size  Total Size  Total Time  Name\n",
      "    5144  24.798KB  4.0000KB  0.9961MB  124.5742MB  41.59637ms  Host To Device\n",
      "    1689  155.13KB  4.0000KB  0.9961MB  255.8750MB  96.33310ms  Device To Host\n",
      "Total CPU Page faults: 1150\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcba6431-ecfa-4d1d-8767-9b07a9110d17",
   "metadata": {},
   "source": [
    "# Variant 3.0 - Grid Stride Loop with Prefetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d448a7f2-2596-42d1-b7aa-4b6618348517",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile CUDA_var3.cu\n",
    "// prefetch\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "//CUDA kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "  float *A,*B,*C; \n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, INT_ARRAY_BYTES);\n",
    "\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "// ****init array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    A[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "    B[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    " //\"Prefetch data\" from CPU-GPU\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// setup CUDA kernel\n",
    "    size_t numThreads = 1024;\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function ***\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks, numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    kernel_C <<<numBlocks, numThreads>>> (ARRAY_SIZE,A,B,C,idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize(); \n",
    "\n",
    "//\"Prefetch data\" from GPU-CPU\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "\n",
    "//error checking\n",
    "    size_t err_count = 0;\n",
    "    for (int i=0; i<ARRAY_SIZE; i++){\n",
    "        if(idx[i] == 0) {\n",
    "            if(C[i] != A[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "        else if (idx[i] == 1) {\n",
    "            if(C[i] != B[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "  printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
    "\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(C);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc20dc8-3622-46ec-9924-ae5fb7035e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var3.cu -o CUDA_var3 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aafe0fd-a19c-4eb8-865b-284ed0604610",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5373b40-2dbb-40a8-a641-e01f1475922a",
   "metadata": {},
   "source": [
    "# Variant 4.0 - Grid Stride Loop with Prefetch and Page Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020a7737-1ddb-4031-9e4d-f99222e66b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile CUDA_var4.cu\n",
    "//prefetch + page creation\n",
    "// page creation responsible gpu fault page\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "//CUDA kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "  float *A,*B,*C; \n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, INT_ARRAY_BYTES);\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "//\"prefetch data\" to create CPU page memory\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "//\"prefetch data\" to create GPU page memory\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// ****init array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    A[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "    B[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    "//\"Prefetch data\" from CPU-GPU\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// setup CUDA kernel\n",
    "    size_t numThreads = 1024;   \n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function ***\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks, numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    kernel_C <<<numBlocks, numThreads>>> (ARRAY_SIZE,A,B,C,idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "  //\"Prefetch data\" from GPU-CPU\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "\n",
    "//error checking\n",
    "    size_t err_count = 0;\n",
    "    for (int i=0; i<ARRAY_SIZE; i++){\n",
    "        if(idx[i] == 0) {\n",
    "            if(C[i] != A[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "        else if (idx[i] == 1) {\n",
    "            if(C[i] != B[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "  printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
    "\n",
    "\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(C);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853e10b1-540f-4ed3-aaa1-15c930185f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var4.cu -o CUDA_var4 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28773e4-33f5-4f41-bc23-aa056be9ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf27c3d-526d-4752-9109-314ead58f1b0",
   "metadata": {},
   "source": [
    "# Variant 5.0 - Grid Stride Loop with Prefetch and Page Creation + mem advise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164372f7-2a1d-4683-8c52-6607404c7c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile CUDA_var5.cu\n",
    "//prefetch + page creation + memadvise\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "//CUDA kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "//declare array\n",
    "  float *A,*B,*C; \n",
    "  int *idx;\n",
    "  cudaMallocManaged(&A, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMallocManaged(&idx, INT_ARRAY_BYTES);\n",
    "\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "// memory advise\n",
    "   cudaMemAdvise(A, FLOAT_ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
    "   cudaMemAdvise(A, FLOAT_ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
    "   cudaMemAdvise(B, FLOAT_ARRAY_BYTES, cudaMemAdviseSetPreferredLocation, cudaCpuDeviceId);\n",
    "   cudaMemAdvise(B, FLOAT_ARRAY_BYTES, cudaMemAdviseSetReadMostly, cudaCpuDeviceId);\n",
    "\n",
    "//\"prefetch data\" to create CPU page memory\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "//\"prefetch data\" to create GPU page memory\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// ****init array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    A[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "    B[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    "\n",
    "\n",
    " //\"Prefetch data\" from CPU-GPU\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,device,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,device,NULL);\n",
    "\n",
    "// setup CUDA kernel\n",
    "    size_t numThreads = 1024;   // what if numThreads>1024, numThreads<1024?\n",
    "    size_t numBlocks = (ARRAY_SIZE + numThreads-1) / numThreads;\n",
    "\n",
    "  printf(\"*** function ***\\n\");\n",
    "  printf(\"numElements = %lu\\n\", ARRAY_SIZE);\n",
    "  printf(\"numBlocks = %lu, numThreads = %lu \\n\",numBlocks, numThreads);\n",
    "  for (size_t i=0; i<loope;i++)\n",
    "    kernel_C <<<numBlocks, numThreads>>> (ARRAY_SIZE,A,B,C,idx);\n",
    "//barrier\n",
    "    cudaDeviceSynchronize();\n",
    "\n",
    "  //\"Prefetch data\" from GPU-CPU\n",
    "  cudaMemPrefetchAsync(C,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(A,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(B,FLOAT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "  cudaMemPrefetchAsync(idx,INT_ARRAY_BYTES,cudaCpuDeviceId,NULL);\n",
    "\n",
    "//error checking\n",
    "    size_t err_count = 0;\n",
    "    for (int i=0; i<ARRAY_SIZE; i++){\n",
    "        if(idx[i] == 0) {\n",
    "            if(C[i] != A[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "        else if (idx[i] == 1) {\n",
    "            if(C[i] != B[i]) {\n",
    "                err_count++;\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "  printf(\"Error count(CUDA program): %zu\\n\", err_count);\n",
    "\n",
    "\n",
    "//free memory\n",
    "  cudaFree(A);\n",
    "  cudaFree(B);\n",
    "  cudaFree(C);\n",
    "  cudaFree(idx);\n",
    "  return 0;\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd4a82f-8d7e-44ff-a297-f144050f2718",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var5.cu -o CUDA_var5 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dc4c29-d16f-4529-a1c9-36c8ade23ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88115767-5ecc-4555-9db7-1ed69bcf01bc",
   "metadata": {},
   "source": [
    "# Variant 6.0 - CUDA classic MEMCPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4aabf3-01a1-43d9-9ad2-53b22d5623a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile CUDA_var6.cu\n",
    "//grid stride loop + memcpy\n",
    "// BFF PALANG TOH SO FAR + onting research sa websites HJSHAS\n",
    "// UNFINISHED\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "//CUDA kernel\n",
    "__global__\n",
    "void kernel_C(size_t n, float A[],float B[],float C[],int idx[]){\n",
    "    int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    int stride = blockDim.x * gridDim.x;\n",
    "    for (int i = index; i < n; i += stride)\n",
    "    {\n",
    "        if (A[i] >= B[i]) {\n",
    "            C[i] = A[i];\n",
    "            idx[i] = 0;\n",
    "        }\n",
    "        else {\n",
    "            C[i] = B[i];\n",
    "            idx[i] = 1;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "  const size_t ARRAY_SIZE = 1<<24;\n",
    "  const size_t INT_ARRAY_BYTES = ARRAY_SIZE * sizeof(int);\n",
    "  const size_t FLOAT_ARRAY_BYTES = ARRAY_SIZE * sizeof(float);\n",
    " //number of times the program is to be executed\n",
    "   const size_t loope = 10;\n",
    "\n",
    "//declare array for host allocations\n",
    "  float *h_A,*h_B,*h_C; \n",
    "  int *h_idx;\n",
    "  cudaMalloc(&h_A, FLOAT_ARRAY_BYTES); //we dont use cudaMallocManaged with cudaMemcpy\n",
    "  cudaMalloc(&h_B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMalloc(&h_C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMalloc(&h_idx, INT_ARRAY_BYTES);\n",
    "\n",
    "// ****init host array\n",
    "  int i;\n",
    "  for (i = 0; i < ARRAY_SIZE; i++) {\n",
    "    A[i] = sin(i * 0.0005) * 100.0 + 50.0;\n",
    "    B[i] = cos(i * 0.0003) * 100.0 + 50.0;\n",
    "  }\n",
    "\n",
    "// device allocations\n",
    "  float *d_A,*d_B,*d_C;\n",
    "  int *d_idx;\n",
    "  cudaMalloc(&d_A, FLOAT_ARRAY_BYTES); //we dont use cudaMallocManaged with cudaMemcpy\n",
    "  cudaMalloc(&d_B, FLOAT_ARRAY_BYTES);\n",
    "  cudaMalloc(&d_C, FLOAT_ARRAY_BYTES);\n",
    "  cudaMalloc(&d_idx, INT_ARRAY_BYTES);\n",
    "\n",
    "//get gpu id\n",
    "  int device = -1;\n",
    "  cudaGetDevice(&device);\n",
    "\n",
    "// Copy data to device\n",
    "    cudaMemcpy(d_A, h_A, FLOAT_ARRAY_BYTES, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_B, h_B, FLOAT_ARRAY_BYTES, cudaMemcpyHostToDevice);\n",
    "\n",
    "// Kernel launch configuration\n",
    "    int threadsPerBlock = 256;\n",
    "    int blocksPerGrid = (ARRAY_SIZE + threadsPerBlock - 1) / threadsPerBlock;\n",
    "\n",
    "// Copy results back to host\n",
    "    cudaMemcpy(h_C, d_C, FLOAT_ARRAY_BYTES, cudaMemcpyDeviceToHost);\n",
    "    cudaMemcpy(h_idx, d_idx, INT_ARRAY_BYTES, cudaMemcpyDeviceToHost);\n",
    "\n",
    "\n",
    "// Free device memory\n",
    "    cudaFree(d_A);\n",
    "    cudaFree(d_B);\n",
    "    cudaFree(d_C);\n",
    "    cudaFree(d_idx);\n",
    "\n",
    "// Free host memory\n",
    "    free(h_A);\n",
    "    free(h_B);\n",
    "    free(h_C);\n",
    "    free(h_idx);\n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5719731-db6c-40a0-aabf-ebded2ba59e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvcc CUDA_var6.cu -o CUDA_var6 -Wno-deprecated-gpu-targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a975380-63c1-456d-83cd-cc864431ccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "nvprof ./CUDA_var6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
